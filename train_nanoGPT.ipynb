{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Zb4C1V2Adv4"
      },
      "source": [
        "## Training nanoGPT on Arabic poems"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mVOqNGwGA_c9"
      },
      "source": [
        "### Install packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YTbrMDCIbflt",
        "outputId": "3460f6fd-9594-4465-bfa7-53829e9f957c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting gitpython\n",
            "  Downloading GitPython-3.1.40-py3-none-any.whl (190 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.6/190.6 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gitdb<5,>=4.0.1 (from gitpython)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: smmap, gitdb, gitpython\n",
            "Successfully installed gitdb-4.0.11 gitpython-3.1.40 smmap-5.0.1\n"
          ]
        }
      ],
      "source": [
        "!pip install gitpython"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P4zvLQDTdHxS",
        "outputId": "7d63ee24-2a6a-4c2b-fa49-f3fa886bf055"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.0+cu118)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.23.5)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.15.0-py3-none-any.whl (521 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m521.2/521.2 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tiktoken\n",
            "  Downloading tiktoken-0.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting wandb\n",
            "  Downloading wandb-0.16.0-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m81.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.1)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n",
            "Collecting pyarrow-hotfix (from datasets)\n",
            "  Downloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n",
            "Collecting dill<0.3.8,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Collecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.1)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.1.40)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Collecting sentry-sdk>=1.0.0 (from wandb)\n",
            "  Downloading sentry_sdk-1.38.0-py2.py3-none-any.whl (252 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m252.8/252.8 kB\u001b[0m \u001b[31m29.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0 (from wandb)\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Collecting setproctitle (from wandb)\n",
            "  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.3)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.11.17)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3.post1)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n",
            "Installing collected packages: setproctitle, sentry-sdk, pyarrow-hotfix, docker-pycreds, dill, tiktoken, multiprocess, wandb, datasets\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires openai, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-2.15.0 dill-0.3.7 docker-pycreds-0.4.0 multiprocess-0.70.15 pyarrow-hotfix-0.6 sentry-sdk-1.38.0 setproctitle-1.3.3 tiktoken-0.5.2 wandb-0.16.0\n"
          ]
        }
      ],
      "source": [
        "!pip install torch numpy transformers datasets tiktoken wandb tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o_nEnDD8c1oG"
      },
      "source": [
        "### Change working directory to nanoGPT folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2GX3tcqkb6GD"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.chdir('nanoGPT')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T0Z0xnZLdB8X"
      },
      "source": [
        "### Download & prepare our data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dv1ezcTBFsbw"
      },
      "source": [
        "Our preprocessed data can be found in https://raw.githubusercontent.com/neyadi/arabic_poem/main/input.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p2N3unl1fE8b",
        "outputId": "fb037d5a-b195-4df6-9311-fe17fd899e3c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "length of dataset in characters: 34,389,599\n",
            "all the unique characters: \n",
            " ءآأؤإئابةتثجحخدذرزسشصضطظعغفقكلمنهوىي\n",
            "vocab size: 38\n",
            "train has 30,950,639 tokens\n",
            "val has 3,438,960 tokens\n"
          ]
        }
      ],
      "source": [
        "!python3 data/arabicpoetry_char/prepare.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qPNhduzx-XhF"
      },
      "source": [
        "### Train our models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LYoQlud1Gg0v"
      },
      "source": [
        "#### A. Using default parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yAYRiBfzGx2I",
        "outputId": "7e71122f-c267-4479-b21b-3f2d9504a624"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overriding config with config/train_arabicpoetry_char.py:\n",
            "# train a miniature character-level arabicpoetry model\n",
            "\n",
            "out_dir = 'out-arabicpoetry-char'\n",
            "eval_interval = 250\n",
            "eval_iters = 200\n",
            "log_interval = 10 \n",
            "\n",
            "always_save_checkpoint = False\n",
            "\n",
            "wandb_log = False \n",
            "wandb_project = 'arabicpoetry-char'\n",
            "wandb_run_name = 'mini-gpt'\n",
            "\n",
            "dataset = 'arabicpoetry_char'\n",
            "gradient_accumulation_steps = 1\n",
            "batch_size = 64\n",
            "block_size = 256\n",
            "\n",
            "n_layer = 6\n",
            "n_head = 6\n",
            "n_embd = 384\n",
            "dropout = 0.2\n",
            "\n",
            "learning_rate = 1e-3 \n",
            "max_iters = 5000\n",
            "lr_decay_iters = 5000 \n",
            "min_lr = 1e-4 \n",
            "beta2 = 0.99 \n",
            "\n",
            "warmup_iters = 100 \n",
            "Overriding: out_dir = out-arabicpoetry-char-default\n",
            "tokens per iteration will be: 16,384\n",
            "found vocab_size = 38 (inside data/arabicpoetry_char/meta.pkl)\n",
            "Initializing a new model from scratch\n",
            "number of parameters: 10.64M\n",
            "num decayed parameter tensors: 26, with 10,729,728 parameters\n",
            "num non-decayed parameter tensors: 13, with 4,992 parameters\n",
            "using fused AdamW: True\n",
            "compiling the model... (takes a ~minute)\n",
            "step 0: train loss 3.7268, val loss 3.7269\n",
            "iter 0: loss 3.7006, time 40212.05ms, mfu -100.00%\n",
            "iter 10: loss 2.9138, time 28.72ms, mfu 12.96%\n",
            "iter 20: loss 2.7915, time 29.74ms, mfu 12.92%\n",
            "iter 30: loss 2.7451, time 28.87ms, mfu 12.92%\n",
            "iter 40: loss 2.7112, time 28.88ms, mfu 12.91%\n",
            "iter 50: loss 2.7210, time 28.96ms, mfu 12.91%\n",
            "iter 60: loss 2.6936, time 28.84ms, mfu 12.91%\n",
            "iter 70: loss 2.6927, time 28.86ms, mfu 12.91%\n",
            "iter 80: loss 2.6816, time 29.18ms, mfu 12.89%\n",
            "iter 90: loss 2.6969, time 28.86ms, mfu 12.89%\n",
            "iter 100: loss 2.6676, time 29.05ms, mfu 12.89%\n",
            "iter 110: loss 2.6733, time 28.83ms, mfu 12.89%\n",
            "iter 120: loss 2.6719, time 28.74ms, mfu 12.90%\n",
            "iter 130: loss 2.6544, time 28.88ms, mfu 12.90%\n",
            "iter 140: loss 2.6554, time 28.99ms, mfu 12.89%\n",
            "iter 150: loss 2.6621, time 29.07ms, mfu 12.88%\n",
            "iter 160: loss 2.6336, time 29.24ms, mfu 12.87%\n",
            "iter 170: loss 2.6078, time 28.99ms, mfu 12.86%\n",
            "iter 180: loss 2.6031, time 28.88ms, mfu 12.87%\n",
            "iter 190: loss 2.5914, time 28.97ms, mfu 12.87%\n",
            "iter 200: loss 2.5448, time 28.82ms, mfu 12.87%\n",
            "iter 210: loss 2.4905, time 29.04ms, mfu 12.87%\n",
            "iter 220: loss 2.4729, time 29.01ms, mfu 12.86%\n",
            "iter 230: loss 2.4450, time 28.96ms, mfu 12.86%\n",
            "iter 240: loss 2.4117, time 28.67ms, mfu 12.87%\n",
            "step 250: train loss 2.3432, val loss 2.3394\n",
            "saving checkpoint to out-arabicpoetry-char-default\n",
            "iter 250: loss 2.3845, time 4742.02ms, mfu 11.59%\n",
            "iter 260: loss 2.3540, time 28.89ms, mfu 11.72%\n",
            "iter 270: loss 2.3412, time 28.92ms, mfu 11.84%\n",
            "iter 280: loss 2.3259, time 28.90ms, mfu 11.94%\n",
            "iter 290: loss 2.3099, time 29.24ms, mfu 12.02%\n",
            "iter 300: loss 2.2949, time 28.94ms, mfu 12.11%\n",
            "iter 310: loss 2.2983, time 28.84ms, mfu 12.19%\n",
            "iter 320: loss 2.2582, time 29.00ms, mfu 12.25%\n",
            "iter 330: loss 2.2668, time 28.98ms, mfu 12.31%\n",
            "iter 340: loss 2.2546, time 29.03ms, mfu 12.36%\n",
            "iter 350: loss 2.2324, time 28.93ms, mfu 12.41%\n",
            "iter 360: loss 2.2266, time 29.26ms, mfu 12.44%\n",
            "iter 370: loss 2.2150, time 29.01ms, mfu 12.48%\n",
            "iter 380: loss 2.1957, time 29.09ms, mfu 12.51%\n",
            "iter 390: loss 2.1918, time 29.01ms, mfu 12.55%\n",
            "iter 400: loss 2.1744, time 29.11ms, mfu 12.57%\n",
            "iter 410: loss 2.1609, time 28.77ms, mfu 12.61%\n",
            "iter 420: loss 2.1503, time 28.97ms, mfu 12.63%\n",
            "iter 430: loss 2.1587, time 29.24ms, mfu 12.64%\n",
            "iter 440: loss 2.1498, time 29.17ms, mfu 12.65%\n",
            "iter 450: loss 2.1325, time 29.12ms, mfu 12.67%\n",
            "iter 460: loss 2.1358, time 29.03ms, mfu 12.68%\n",
            "iter 470: loss 2.1492, time 29.05ms, mfu 12.70%\n",
            "iter 480: loss 2.1119, time 28.91ms, mfu 12.71%\n",
            "iter 490: loss 2.1064, time 28.93ms, mfu 12.73%\n",
            "step 500: train loss 2.0419, val loss 2.0375\n",
            "saving checkpoint to out-arabicpoetry-char-default\n",
            "iter 500: loss 2.1076, time 4818.27ms, mfu 11.46%\n",
            "iter 510: loss 2.1019, time 29.12ms, mfu 11.60%\n",
            "iter 520: loss 2.1158, time 28.98ms, mfu 11.72%\n",
            "iter 530: loss 2.1161, time 29.06ms, mfu 11.83%\n",
            "iter 540: loss 2.1169, time 28.95ms, mfu 11.93%\n",
            "iter 550: loss 2.0860, time 28.74ms, mfu 12.04%\n",
            "iter 560: loss 2.0678, time 29.14ms, mfu 12.11%\n",
            "iter 570: loss 2.1030, time 29.09ms, mfu 12.18%\n",
            "iter 580: loss 2.0818, time 28.97ms, mfu 12.25%\n",
            "iter 590: loss 2.0778, time 28.93ms, mfu 12.31%\n",
            "iter 600: loss 2.0735, time 28.93ms, mfu 12.36%\n",
            "iter 610: loss 2.0520, time 28.91ms, mfu 12.42%\n",
            "iter 620: loss 2.0333, time 29.24ms, mfu 12.45%\n",
            "iter 630: loss 2.0460, time 29.07ms, mfu 12.48%\n",
            "iter 640: loss 2.0394, time 28.93ms, mfu 12.52%\n",
            "iter 650: loss 2.0280, time 29.20ms, mfu 12.54%\n",
            "iter 660: loss 2.0257, time 29.09ms, mfu 12.57%\n",
            "iter 670: loss 2.0469, time 28.83ms, mfu 12.60%\n",
            "iter 680: loss 2.0243, time 28.98ms, mfu 12.63%\n",
            "iter 690: loss 2.0298, time 29.28ms, mfu 12.64%\n",
            "iter 700: loss 2.0046, time 29.20ms, mfu 12.65%\n",
            "iter 710: loss 2.0063, time 28.87ms, mfu 12.67%\n",
            "iter 720: loss 2.0008, time 29.10ms, mfu 12.69%\n",
            "iter 730: loss 2.0201, time 28.92ms, mfu 12.70%\n",
            "iter 740: loss 2.0082, time 28.92ms, mfu 12.72%\n",
            "step 750: train loss 1.9269, val loss 1.9236\n",
            "saving checkpoint to out-arabicpoetry-char-default\n",
            "iter 750: loss 2.0098, time 4819.46ms, mfu 11.46%\n",
            "iter 760: loss 1.9866, time 29.04ms, mfu 11.59%\n",
            "iter 770: loss 1.9659, time 28.96ms, mfu 11.72%\n",
            "iter 780: loss 1.9906, time 29.26ms, mfu 11.82%\n",
            "iter 790: loss 1.9870, time 29.06ms, mfu 11.92%\n",
            "iter 800: loss 1.9789, time 28.90ms, mfu 12.02%\n",
            "iter 810: loss 1.9682, time 29.03ms, mfu 12.10%\n",
            "iter 820: loss 1.9650, time 29.18ms, mfu 12.16%\n",
            "iter 830: loss 1.9616, time 29.03ms, mfu 12.23%\n",
            "iter 840: loss 1.9647, time 29.01ms, mfu 12.29%\n",
            "iter 850: loss 1.9683, time 28.88ms, mfu 12.35%\n",
            "iter 860: loss 1.9594, time 28.66ms, mfu 12.41%\n",
            "iter 870: loss 1.9507, time 28.85ms, mfu 12.46%\n",
            "iter 880: loss 1.9802, time 29.07ms, mfu 12.50%\n",
            "iter 890: loss 1.9335, time 29.30ms, mfu 12.52%\n",
            "iter 900: loss 1.9209, time 28.94ms, mfu 12.55%\n",
            "iter 910: loss 1.9526, time 28.77ms, mfu 12.59%\n",
            "iter 920: loss 1.9449, time 29.04ms, mfu 12.61%\n",
            "iter 930: loss 1.9141, time 29.02ms, mfu 12.64%\n",
            "iter 940: loss 1.9525, time 28.93ms, mfu 12.66%\n",
            "iter 950: loss 1.9165, time 29.01ms, mfu 12.68%\n",
            "iter 960: loss 1.9296, time 28.96ms, mfu 12.69%\n",
            "iter 970: loss 1.9528, time 29.20ms, mfu 12.70%\n",
            "iter 980: loss 1.9106, time 29.02ms, mfu 12.71%\n",
            "iter 990: loss 1.9204, time 29.04ms, mfu 12.72%\n",
            "step 1000: train loss 1.8522, val loss 1.8469\n",
            "saving checkpoint to out-arabicpoetry-char-default\n",
            "iter 1000: loss 1.8953, time 4795.14ms, mfu 11.46%\n",
            "iter 1010: loss 1.9180, time 29.04ms, mfu 11.59%\n",
            "iter 1020: loss 1.9180, time 29.27ms, mfu 11.71%\n",
            "iter 1030: loss 1.9017, time 29.47ms, mfu 11.80%\n",
            "iter 1040: loss 1.8933, time 28.95ms, mfu 11.91%\n",
            "iter 1050: loss 1.8972, time 29.24ms, mfu 11.99%\n",
            "iter 1060: loss 1.8992, time 29.12ms, mfu 12.07%\n",
            "iter 1070: loss 1.9040, time 29.15ms, mfu 12.14%\n",
            "iter 1080: loss 1.8947, time 29.13ms, mfu 12.20%\n",
            "iter 1090: loss 1.8889, time 29.25ms, mfu 12.26%\n",
            "iter 1100: loss 1.8960, time 29.09ms, mfu 12.31%\n",
            "iter 1110: loss 1.8807, time 29.21ms, mfu 12.35%\n",
            "iter 1120: loss 1.9016, time 28.85ms, mfu 12.41%\n",
            "iter 1130: loss 1.8814, time 28.93ms, mfu 12.45%\n",
            "iter 1140: loss 1.8774, time 29.42ms, mfu 12.47%\n",
            "iter 1150: loss 1.8823, time 29.06ms, mfu 12.51%\n",
            "iter 1160: loss 1.8673, time 29.02ms, mfu 12.54%\n",
            "iter 1170: loss 1.8825, time 28.99ms, mfu 12.57%\n",
            "iter 1180: loss 1.8691, time 29.04ms, mfu 12.60%\n",
            "iter 1190: loss 1.8689, time 28.95ms, mfu 12.62%\n",
            "iter 1200: loss 1.8690, time 29.81ms, mfu 12.61%\n",
            "iter 1210: loss 1.8807, time 29.44ms, mfu 12.61%\n",
            "iter 1220: loss 1.8717, time 29.04ms, mfu 12.63%\n",
            "iter 1230: loss 1.8834, time 29.00ms, mfu 12.65%\n",
            "iter 1240: loss 1.8754, time 28.93ms, mfu 12.67%\n",
            "step 1250: train loss 1.8043, val loss 1.8013\n",
            "saving checkpoint to out-arabicpoetry-char-default\n",
            "iter 1250: loss 1.8844, time 4853.21ms, mfu 11.42%\n",
            "iter 1260: loss 1.8578, time 29.05ms, mfu 11.56%\n",
            "iter 1270: loss 1.8685, time 29.07ms, mfu 11.68%\n",
            "iter 1280: loss 1.8644, time 28.85ms, mfu 11.80%\n",
            "iter 1290: loss 1.8511, time 29.30ms, mfu 11.89%\n",
            "iter 1300: loss 1.8572, time 29.22ms, mfu 11.98%\n",
            "iter 1310: loss 1.8642, time 29.19ms, mfu 12.06%\n",
            "iter 1320: loss 1.8791, time 29.36ms, mfu 12.12%\n",
            "iter 1330: loss 1.8415, time 29.05ms, mfu 12.19%\n",
            "iter 1340: loss 1.8700, time 29.01ms, mfu 12.25%\n",
            "iter 1350: loss 1.8429, time 28.99ms, mfu 12.31%\n",
            "iter 1360: loss 1.8548, time 29.07ms, mfu 12.36%\n",
            "iter 1370: loss 1.8605, time 29.09ms, mfu 12.40%\n",
            "iter 1380: loss 1.8477, time 29.06ms, mfu 12.44%\n",
            "iter 1390: loss 1.8585, time 29.39ms, mfu 12.47%\n",
            "iter 1400: loss 1.8601, time 28.93ms, mfu 12.51%\n",
            "iter 1410: loss 1.8160, time 28.93ms, mfu 12.54%\n",
            "iter 1420: loss 1.8323, time 29.07ms, mfu 12.57%\n",
            "iter 1430: loss 1.8350, time 29.20ms, mfu 12.59%\n",
            "iter 1440: loss 1.8458, time 29.18ms, mfu 12.60%\n",
            "iter 1450: loss 1.8287, time 28.97ms, mfu 12.63%\n",
            "iter 1460: loss 1.8666, time 28.92ms, mfu 12.65%\n",
            "iter 1470: loss 1.8181, time 28.88ms, mfu 12.68%\n",
            "iter 1480: loss 1.8199, time 29.16ms, mfu 12.69%\n",
            "iter 1490: loss 1.8320, time 29.18ms, mfu 12.69%\n",
            "step 1500: train loss 1.7702, val loss 1.7675\n",
            "saving checkpoint to out-arabicpoetry-char-default\n",
            "iter 1500: loss 1.8301, time 4818.67ms, mfu 11.43%\n",
            "iter 1510: loss 1.8391, time 29.16ms, mfu 11.57%\n",
            "iter 1520: loss 1.8635, time 29.16ms, mfu 11.69%\n",
            "iter 1530: loss 1.8322, time 29.05ms, mfu 11.80%\n",
            "iter 1540: loss 1.8739, time 28.76ms, mfu 11.91%\n",
            "iter 1550: loss 1.8305, time 28.83ms, mfu 12.01%\n",
            "iter 1560: loss 1.8232, time 29.01ms, mfu 12.10%\n",
            "iter 1570: loss 1.7968, time 29.17ms, mfu 12.16%\n",
            "iter 1580: loss 1.8087, time 29.49ms, mfu 12.21%\n",
            "iter 1590: loss 1.8368, time 29.05ms, mfu 12.27%\n",
            "iter 1600: loss 1.8187, time 28.80ms, mfu 12.34%\n",
            "iter 1610: loss 1.8124, time 29.17ms, mfu 12.38%\n",
            "iter 1620: loss 1.8183, time 29.00ms, mfu 12.42%\n",
            "iter 1630: loss 1.8067, time 28.93ms, mfu 12.47%\n",
            "iter 1640: loss 1.8253, time 28.92ms, mfu 12.51%\n",
            "iter 1650: loss 1.7912, time 29.16ms, mfu 12.53%\n",
            "iter 1660: loss 1.8068, time 29.23ms, mfu 12.56%\n",
            "iter 1670: loss 1.8232, time 29.10ms, mfu 12.58%\n",
            "iter 1680: loss 1.8170, time 29.05ms, mfu 12.60%\n",
            "iter 1690: loss 1.8064, time 29.05ms, mfu 12.62%\n",
            "iter 1700: loss 1.7739, time 29.14ms, mfu 12.64%\n",
            "iter 1710: loss 1.8156, time 29.17ms, mfu 12.65%\n",
            "iter 1720: loss 1.7899, time 29.13ms, mfu 12.66%\n",
            "iter 1730: loss 1.8108, time 29.16ms, mfu 12.68%\n",
            "iter 1740: loss 1.8061, time 29.12ms, mfu 12.69%\n",
            "step 1750: train loss 1.7491, val loss 1.7484\n",
            "saving checkpoint to out-arabicpoetry-char-default\n",
            "iter 1750: loss 1.7922, time 4848.35ms, mfu 11.43%\n",
            "iter 1760: loss 1.8447, time 28.98ms, mfu 11.57%\n",
            "iter 1770: loss 1.8112, time 28.94ms, mfu 11.70%\n",
            "iter 1780: loss 1.8104, time 29.04ms, mfu 11.81%\n",
            "iter 1790: loss 1.8031, time 29.10ms, mfu 11.91%\n",
            "iter 1800: loss 1.7980, time 29.34ms, mfu 11.99%\n",
            "iter 1810: loss 1.7877, time 29.23ms, mfu 12.06%\n",
            "iter 1820: loss 1.8080, time 28.98ms, mfu 12.14%\n",
            "iter 1830: loss 1.7739, time 29.13ms, mfu 12.20%\n",
            "iter 1840: loss 1.7800, time 29.26ms, mfu 12.26%\n",
            "iter 1850: loss 1.7882, time 28.97ms, mfu 12.32%\n",
            "iter 1860: loss 1.7999, time 29.16ms, mfu 12.36%\n",
            "iter 1870: loss 1.7967, time 29.12ms, mfu 12.40%\n",
            "iter 1880: loss 1.7905, time 28.93ms, mfu 12.45%\n",
            "iter 1890: loss 1.7887, time 29.27ms, mfu 12.48%\n",
            "iter 1900: loss 1.8048, time 28.91ms, mfu 12.52%\n",
            "iter 1910: loss 1.7863, time 29.21ms, mfu 12.54%\n",
            "iter 1920: loss 1.7893, time 29.26ms, mfu 12.56%\n",
            "iter 1930: loss 1.7647, time 29.21ms, mfu 12.58%\n",
            "iter 1940: loss 1.7784, time 29.08ms, mfu 12.60%\n",
            "iter 1950: loss 1.7838, time 29.01ms, mfu 12.62%\n",
            "iter 1960: loss 1.7788, time 29.20ms, mfu 12.64%\n",
            "iter 1970: loss 1.7966, time 29.09ms, mfu 12.65%\n",
            "iter 1980: loss 1.7695, time 29.17ms, mfu 12.66%\n",
            "iter 1990: loss 1.8048, time 28.94ms, mfu 12.68%\n",
            "step 2000: train loss 1.7254, val loss 1.7270\n",
            "saving checkpoint to out-arabicpoetry-char-default\n",
            "iter 2000: loss 1.7790, time 4866.12ms, mfu 11.42%\n",
            "iter 2010: loss 1.7962, time 29.13ms, mfu 11.56%\n",
            "iter 2020: loss 1.7937, time 29.19ms, mfu 11.68%\n",
            "iter 2030: loss 1.7666, time 29.06ms, mfu 11.79%\n",
            "iter 2040: loss 1.7760, time 29.08ms, mfu 11.89%\n",
            "iter 2050: loss 1.7814, time 29.03ms, mfu 11.99%\n",
            "iter 2060: loss 1.7681, time 29.10ms, mfu 12.07%\n",
            "iter 2070: loss 1.7657, time 29.08ms, mfu 12.14%\n",
            "iter 2080: loss 1.7715, time 29.00ms, mfu 12.21%\n",
            "iter 2090: loss 1.7659, time 29.14ms, mfu 12.27%\n",
            "iter 2100: loss 1.7701, time 29.30ms, mfu 12.31%\n",
            "iter 2110: loss 1.7599, time 29.05ms, mfu 12.36%\n",
            "iter 2120: loss 1.7740, time 29.17ms, mfu 12.40%\n",
            "iter 2130: loss 1.7880, time 29.02ms, mfu 12.44%\n",
            "iter 2140: loss 1.7792, time 29.07ms, mfu 12.48%\n",
            "iter 2150: loss 1.7447, time 28.97ms, mfu 12.52%\n",
            "iter 2160: loss 1.7557, time 29.20ms, mfu 12.54%\n",
            "iter 2170: loss 1.7792, time 29.41ms, mfu 12.55%\n",
            "iter 2180: loss 1.7585, time 29.12ms, mfu 12.58%\n",
            "iter 2190: loss 1.7668, time 29.18ms, mfu 12.59%\n",
            "iter 2200: loss 1.7773, time 29.34ms, mfu 12.60%\n",
            "iter 2210: loss 1.7491, time 29.32ms, mfu 12.61%\n",
            "iter 2220: loss 1.7859, time 29.20ms, mfu 12.63%\n",
            "iter 2230: loss 1.7855, time 29.19ms, mfu 12.64%\n",
            "iter 2240: loss 1.7393, time 29.16ms, mfu 12.65%\n",
            "step 2250: train loss 1.7088, val loss 1.7089\n",
            "saving checkpoint to out-arabicpoetry-char-default\n",
            "iter 2250: loss 1.7547, time 4858.38ms, mfu 11.39%\n",
            "iter 2260: loss 1.7426, time 29.19ms, mfu 11.53%\n",
            "iter 2270: loss 1.7393, time 29.00ms, mfu 11.66%\n",
            "iter 2280: loss 1.7531, time 29.13ms, mfu 11.77%\n",
            "iter 2290: loss 1.7741, time 29.01ms, mfu 11.88%\n",
            "iter 2300: loss 1.7391, time 28.90ms, mfu 11.98%\n",
            "iter 2310: loss 1.7547, time 29.32ms, mfu 12.05%\n",
            "iter 2320: loss 1.7601, time 29.13ms, mfu 12.12%\n",
            "iter 2330: loss 1.7384, time 29.24ms, mfu 12.19%\n",
            "iter 2340: loss 1.7592, time 29.21ms, mfu 12.24%\n",
            "iter 2350: loss 1.7417, time 29.19ms, mfu 12.29%\n",
            "iter 2360: loss 1.7260, time 29.06ms, mfu 12.34%\n",
            "iter 2370: loss 1.7434, time 28.98ms, mfu 12.39%\n",
            "iter 2380: loss 1.7430, time 29.32ms, mfu 12.43%\n",
            "iter 2390: loss 1.7486, time 29.25ms, mfu 12.46%\n",
            "iter 2400: loss 1.7406, time 29.03ms, mfu 12.49%\n",
            "iter 2410: loss 1.7355, time 29.04ms, mfu 12.53%\n",
            "iter 2420: loss 1.7594, time 29.24ms, mfu 12.55%\n",
            "iter 2430: loss 1.7544, time 29.03ms, mfu 12.57%\n",
            "iter 2440: loss 1.7215, time 29.24ms, mfu 12.59%\n",
            "iter 2450: loss 1.7574, time 28.92ms, mfu 12.62%\n",
            "iter 2460: loss 1.7454, time 29.04ms, mfu 12.64%\n",
            "iter 2470: loss 1.7699, time 29.12ms, mfu 12.65%\n",
            "iter 2480: loss 1.7491, time 29.16ms, mfu 12.67%\n",
            "iter 2490: loss 1.7465, time 29.25ms, mfu 12.67%\n",
            "step 2500: train loss 1.6901, val loss 1.6935\n",
            "saving checkpoint to out-arabicpoetry-char-default\n",
            "iter 2500: loss 1.7317, time 4883.92ms, mfu 11.41%\n",
            "iter 2510: loss 1.7314, time 29.09ms, mfu 11.55%\n",
            "iter 2520: loss 1.7492, time 29.23ms, mfu 11.67%\n",
            "iter 2530: loss 1.7090, time 29.12ms, mfu 11.78%\n",
            "iter 2540: loss 1.7565, time 29.16ms, mfu 11.88%\n",
            "iter 2550: loss 1.7604, time 28.96ms, mfu 11.98%\n",
            "iter 2560: loss 1.7506, time 29.12ms, mfu 12.06%\n",
            "iter 2570: loss 1.7506, time 28.99ms, mfu 12.14%\n",
            "iter 2580: loss 1.7273, time 29.13ms, mfu 12.20%\n",
            "iter 2590: loss 1.6972, time 29.24ms, mfu 12.25%\n",
            "iter 2600: loss 1.7654, time 29.10ms, mfu 12.31%\n",
            "iter 2610: loss 1.7366, time 28.91ms, mfu 12.36%\n",
            "iter 2620: loss 1.7340, time 29.19ms, mfu 12.40%\n",
            "iter 2630: loss 1.7557, time 29.46ms, mfu 12.43%\n",
            "iter 2640: loss 1.7167, time 29.12ms, mfu 12.46%\n",
            "iter 2650: loss 1.7418, time 29.02ms, mfu 12.50%\n",
            "iter 2660: loss 1.7366, time 29.07ms, mfu 12.53%\n",
            "iter 2670: loss 1.7007, time 29.22ms, mfu 12.55%\n",
            "iter 2680: loss 1.7259, time 29.28ms, mfu 12.57%\n",
            "iter 2690: loss 1.7223, time 29.33ms, mfu 12.58%\n",
            "iter 2700: loss 1.7181, time 29.18ms, mfu 12.60%\n",
            "iter 2710: loss 1.7605, time 29.19ms, mfu 12.61%\n",
            "iter 2720: loss 1.7154, time 29.22ms, mfu 12.63%\n",
            "iter 2730: loss 1.7343, time 29.12ms, mfu 12.64%\n",
            "iter 2740: loss 1.7645, time 29.08ms, mfu 12.66%\n",
            "step 2750: train loss 1.6744, val loss 1.6783\n",
            "saving checkpoint to out-arabicpoetry-char-default\n",
            "iter 2750: loss 1.7294, time 4891.14ms, mfu 11.40%\n",
            "iter 2760: loss 1.7361, time 29.21ms, mfu 11.53%\n",
            "iter 2770: loss 1.7309, time 29.50ms, mfu 11.64%\n",
            "iter 2780: loss 1.7401, time 29.02ms, mfu 11.76%\n",
            "iter 2790: loss 1.7306, time 28.81ms, mfu 11.88%\n",
            "iter 2800: loss 1.7443, time 29.22ms, mfu 11.96%\n",
            "iter 2810: loss 1.7107, time 29.34ms, mfu 12.04%\n",
            "iter 2820: loss 1.7268, time 29.15ms, mfu 12.11%\n",
            "iter 2830: loss 1.7338, time 29.34ms, mfu 12.17%\n",
            "iter 2840: loss 1.7114, time 29.06ms, mfu 12.23%\n",
            "iter 2850: loss 1.7625, time 29.20ms, mfu 12.28%\n",
            "iter 2860: loss 1.7121, time 29.03ms, mfu 12.34%\n",
            "iter 2870: loss 1.7056, time 29.23ms, mfu 12.38%\n",
            "iter 2880: loss 1.7246, time 29.10ms, mfu 12.42%\n",
            "iter 2890: loss 1.7393, time 29.36ms, mfu 12.45%\n",
            "iter 2900: loss 1.7180, time 29.30ms, mfu 12.47%\n",
            "iter 2910: loss 1.7055, time 29.20ms, mfu 12.50%\n",
            "iter 2920: loss 1.7362, time 29.15ms, mfu 12.53%\n",
            "iter 2930: loss 1.7193, time 29.09ms, mfu 12.55%\n",
            "iter 2940: loss 1.7180, time 29.08ms, mfu 12.58%\n",
            "iter 2950: loss 1.7072, time 29.18ms, mfu 12.60%\n",
            "iter 2960: loss 1.6838, time 29.06ms, mfu 12.62%\n",
            "iter 2970: loss 1.7376, time 29.17ms, mfu 12.63%\n",
            "iter 2980: loss 1.7310, time 29.19ms, mfu 12.65%\n",
            "iter 2990: loss 1.7274, time 29.20ms, mfu 12.66%\n",
            "step 3000: train loss 1.6608, val loss 1.6648\n",
            "saving checkpoint to out-arabicpoetry-char-default\n",
            "iter 3000: loss 1.7268, time 4868.99ms, mfu 11.40%\n",
            "iter 3010: loss 1.7080, time 29.10ms, mfu 11.54%\n",
            "iter 3020: loss 1.7124, time 29.03ms, mfu 11.67%\n",
            "iter 3030: loss 1.6923, time 29.13ms, mfu 11.78%\n",
            "iter 3040: loss 1.7157, time 28.84ms, mfu 11.89%\n",
            "iter 3050: loss 1.7266, time 29.02ms, mfu 11.98%\n",
            "iter 3060: loss 1.7374, time 29.05ms, mfu 12.07%\n",
            "iter 3070: loss 1.7348, time 29.03ms, mfu 12.14%\n",
            "iter 3080: loss 1.7201, time 29.14ms, mfu 12.21%\n",
            "iter 3090: loss 1.7303, time 29.00ms, mfu 12.27%\n",
            "iter 3100: loss 1.7134, time 29.47ms, mfu 12.31%\n",
            "iter 3110: loss 1.7104, time 29.15ms, mfu 12.35%\n",
            "iter 3120: loss 1.6952, time 29.24ms, mfu 12.39%\n",
            "iter 3130: loss 1.6980, time 29.20ms, mfu 12.43%\n",
            "iter 3140: loss 1.7145, time 29.04ms, mfu 12.47%\n",
            "iter 3150: loss 1.7188, time 29.13ms, mfu 12.50%\n",
            "iter 3160: loss 1.6952, time 29.26ms, mfu 12.52%\n",
            "iter 3170: loss 1.7128, time 28.97ms, mfu 12.55%\n",
            "iter 3180: loss 1.7232, time 29.32ms, mfu 12.57%\n",
            "iter 3190: loss 1.7019, time 29.20ms, mfu 12.59%\n",
            "iter 3200: loss 1.7529, time 29.06ms, mfu 12.61%\n",
            "iter 3210: loss 1.7051, time 29.20ms, mfu 12.62%\n",
            "iter 3220: loss 1.7003, time 29.33ms, mfu 12.63%\n",
            "iter 3230: loss 1.7176, time 29.19ms, mfu 12.64%\n",
            "iter 3240: loss 1.7126, time 29.20ms, mfu 12.65%\n",
            "step 3250: train loss 1.6476, val loss 1.6534\n",
            "saving checkpoint to out-arabicpoetry-char-default\n",
            "iter 3250: loss 1.6941, time 4865.00ms, mfu 11.40%\n",
            "iter 3260: loss 1.6848, time 29.44ms, mfu 11.52%\n",
            "iter 3270: loss 1.7052, time 29.00ms, mfu 11.65%\n",
            "iter 3280: loss 1.6980, time 29.17ms, mfu 11.76%\n",
            "iter 3290: loss 1.6943, time 28.96ms, mfu 11.87%\n",
            "iter 3300: loss 1.6833, time 29.25ms, mfu 11.96%\n",
            "iter 3310: loss 1.6791, time 28.89ms, mfu 12.05%\n",
            "iter 3320: loss 1.6974, time 29.11ms, mfu 12.13%\n",
            "iter 3330: loss 1.6719, time 29.35ms, mfu 12.18%\n",
            "iter 3340: loss 1.6921, time 29.24ms, mfu 12.24%\n",
            "iter 3350: loss 1.6931, time 29.06ms, mfu 12.29%\n",
            "iter 3360: loss 1.6627, time 28.99ms, mfu 12.35%\n",
            "iter 3370: loss 1.6781, time 29.19ms, mfu 12.39%\n",
            "iter 3380: loss 1.6626, time 29.22ms, mfu 12.42%\n",
            "iter 3390: loss 1.7087, time 29.10ms, mfu 12.46%\n",
            "iter 3400: loss 1.6828, time 29.09ms, mfu 12.49%\n",
            "iter 3410: loss 1.6863, time 29.14ms, mfu 12.52%\n",
            "iter 3420: loss 1.6829, time 29.28ms, mfu 12.54%\n",
            "iter 3430: loss 1.7091, time 29.15ms, mfu 12.57%\n",
            "iter 3440: loss 1.7185, time 29.22ms, mfu 12.58%\n",
            "iter 3450: loss 1.6673, time 29.13ms, mfu 12.60%\n",
            "iter 3460: loss 1.6859, time 29.21ms, mfu 12.62%\n",
            "iter 3470: loss 1.6913, time 29.15ms, mfu 12.63%\n",
            "iter 3480: loss 1.6979, time 29.11ms, mfu 12.65%\n",
            "iter 3490: loss 1.7021, time 29.36ms, mfu 12.65%\n",
            "step 3500: train loss 1.6393, val loss 1.6446\n",
            "saving checkpoint to out-arabicpoetry-char-default\n",
            "iter 3500: loss 1.6955, time 4840.67ms, mfu 11.39%\n",
            "iter 3510: loss 1.6741, time 29.14ms, mfu 11.53%\n",
            "iter 3520: loss 1.6960, time 29.18ms, mfu 11.65%\n",
            "iter 3530: loss 1.6907, time 29.08ms, mfu 11.77%\n",
            "iter 3540: loss 1.6736, time 29.01ms, mfu 11.88%\n",
            "iter 3550: loss 1.6613, time 29.32ms, mfu 11.96%\n",
            "iter 3560: loss 1.7113, time 29.20ms, mfu 12.04%\n",
            "iter 3570: loss 1.6820, time 29.33ms, mfu 12.10%\n",
            "iter 3580: loss 1.6855, time 29.10ms, mfu 12.17%\n",
            "iter 3590: loss 1.6772, time 29.20ms, mfu 12.23%\n",
            "iter 3600: loss 1.6928, time 29.07ms, mfu 12.29%\n",
            "iter 3610: loss 1.6847, time 29.36ms, mfu 12.33%\n",
            "iter 3620: loss 1.6795, time 29.64ms, mfu 12.35%\n",
            "iter 3630: loss 1.7043, time 29.41ms, mfu 12.38%\n",
            "iter 3640: loss 1.6889, time 29.16ms, mfu 12.42%\n",
            "iter 3650: loss 1.6784, time 29.54ms, mfu 12.44%\n",
            "iter 3660: loss 1.6820, time 29.13ms, mfu 12.47%\n",
            "iter 3670: loss 1.6549, time 29.09ms, mfu 12.51%\n",
            "iter 3680: loss 1.6782, time 29.15ms, mfu 12.53%\n",
            "iter 3690: loss 1.6847, time 29.09ms, mfu 12.56%\n",
            "iter 3700: loss 1.6773, time 29.03ms, mfu 12.58%\n",
            "iter 3710: loss 1.6883, time 29.07ms, mfu 12.61%\n",
            "iter 3720: loss 1.6824, time 29.33ms, mfu 12.62%\n",
            "iter 3730: loss 1.6729, time 29.20ms, mfu 12.63%\n",
            "iter 3740: loss 1.6800, time 29.13ms, mfu 12.64%\n",
            "step 3750: train loss 1.6259, val loss 1.6346\n",
            "saving checkpoint to out-arabicpoetry-char-default\n",
            "iter 3750: loss 1.6712, time 4858.87ms, mfu 11.39%\n",
            "iter 3760: loss 1.6802, time 28.99ms, mfu 11.53%\n",
            "iter 3770: loss 1.7133, time 29.16ms, mfu 11.66%\n",
            "iter 3780: loss 1.6698, time 29.07ms, mfu 11.77%\n",
            "iter 3790: loss 1.6728, time 29.16ms, mfu 11.87%\n",
            "iter 3800: loss 1.6884, time 29.14ms, mfu 11.96%\n",
            "iter 3810: loss 1.6655, time 29.19ms, mfu 12.04%\n",
            "iter 3820: loss 1.6833, time 29.21ms, mfu 12.11%\n",
            "iter 3830: loss 1.6830, time 29.20ms, mfu 12.18%\n",
            "iter 3840: loss 1.6590, time 29.07ms, mfu 12.24%\n",
            "iter 3850: loss 1.6715, time 29.11ms, mfu 12.29%\n",
            "iter 3860: loss 1.6624, time 29.05ms, mfu 12.35%\n",
            "iter 3870: loss 1.6953, time 29.13ms, mfu 12.39%\n",
            "iter 3880: loss 1.6926, time 28.94ms, mfu 12.44%\n",
            "iter 3890: loss 1.6567, time 29.42ms, mfu 12.46%\n",
            "iter 3900: loss 1.6691, time 29.18ms, mfu 12.49%\n",
            "iter 3910: loss 1.6625, time 28.95ms, mfu 12.53%\n",
            "iter 3920: loss 1.6835, time 29.15ms, mfu 12.55%\n",
            "iter 3930: loss 1.6705, time 29.25ms, mfu 12.57%\n",
            "iter 3940: loss 1.6706, time 29.09ms, mfu 12.59%\n",
            "iter 3950: loss 1.6706, time 29.13ms, mfu 12.61%\n",
            "iter 3960: loss 1.6771, time 28.95ms, mfu 12.64%\n",
            "iter 3970: loss 1.6841, time 29.24ms, mfu 12.65%\n",
            "iter 3980: loss 1.6788, time 29.25ms, mfu 12.65%\n",
            "iter 3990: loss 1.6592, time 29.15ms, mfu 12.67%\n",
            "step 4000: train loss 1.6176, val loss 1.6249\n",
            "saving checkpoint to out-arabicpoetry-char-default\n",
            "iter 4000: loss 1.6697, time 4855.14ms, mfu 11.41%\n",
            "iter 4010: loss 1.6649, time 28.93ms, mfu 11.55%\n",
            "iter 4020: loss 1.6697, time 29.04ms, mfu 11.68%\n",
            "iter 4030: loss 1.6697, time 29.14ms, mfu 11.79%\n",
            "iter 4040: loss 1.6690, time 28.84ms, mfu 11.90%\n",
            "iter 4050: loss 1.6583, time 29.05ms, mfu 11.99%\n",
            "iter 4060: loss 1.6774, time 29.35ms, mfu 12.06%\n",
            "iter 4070: loss 1.6960, time 29.18ms, mfu 12.13%\n",
            "iter 4080: loss 1.6606, time 29.21ms, mfu 12.19%\n",
            "iter 4090: loss 1.6723, time 28.84ms, mfu 12.26%\n",
            "iter 4100: loss 1.6371, time 28.96ms, mfu 12.32%\n",
            "iter 4110: loss 1.6565, time 29.09ms, mfu 12.37%\n",
            "iter 4120: loss 1.6693, time 29.33ms, mfu 12.40%\n",
            "iter 4130: loss 1.6555, time 29.10ms, mfu 12.44%\n",
            "iter 4140: loss 1.6797, time 29.21ms, mfu 12.47%\n",
            "iter 4150: loss 1.6548, time 29.19ms, mfu 12.50%\n",
            "iter 4160: loss 1.6592, time 29.36ms, mfu 12.52%\n",
            "iter 4170: loss 1.6650, time 29.40ms, mfu 12.53%\n",
            "iter 4180: loss 1.6619, time 29.07ms, mfu 12.56%\n",
            "iter 4190: loss 1.6590, time 29.28ms, mfu 12.58%\n",
            "iter 4200: loss 1.6436, time 28.95ms, mfu 12.60%\n",
            "iter 4210: loss 1.6608, time 29.34ms, mfu 12.61%\n",
            "iter 4220: loss 1.6843, time 29.10ms, mfu 12.63%\n",
            "iter 4230: loss 1.6557, time 29.26ms, mfu 12.64%\n",
            "iter 4240: loss 1.6741, time 29.47ms, mfu 12.64%\n",
            "step 4250: train loss 1.6105, val loss 1.6177\n",
            "saving checkpoint to out-arabicpoetry-char-default\n",
            "iter 4250: loss 1.6871, time 4856.95ms, mfu 11.38%\n",
            "iter 4260: loss 1.6832, time 28.90ms, mfu 11.53%\n",
            "iter 4270: loss 1.6520, time 29.06ms, mfu 11.66%\n",
            "iter 4280: loss 1.6732, time 29.15ms, mfu 11.77%\n",
            "iter 4290: loss 1.6754, time 29.09ms, mfu 11.87%\n",
            "iter 4300: loss 1.6699, time 29.11ms, mfu 11.97%\n",
            "iter 4310: loss 1.6964, time 29.24ms, mfu 12.04%\n",
            "iter 4320: loss 1.6508, time 29.15ms, mfu 12.11%\n",
            "iter 4330: loss 1.6654, time 29.17ms, mfu 12.18%\n",
            "iter 4340: loss 1.6424, time 29.11ms, mfu 12.24%\n",
            "iter 4350: loss 1.6487, time 29.06ms, mfu 12.30%\n",
            "iter 4360: loss 1.6735, time 29.13ms, mfu 12.35%\n",
            "iter 4370: loss 1.6368, time 29.43ms, mfu 12.38%\n",
            "iter 4380: loss 1.6789, time 29.22ms, mfu 12.41%\n",
            "iter 4390: loss 1.6465, time 29.21ms, mfu 12.45%\n",
            "iter 4400: loss 1.6708, time 29.13ms, mfu 12.48%\n",
            "iter 4410: loss 1.6874, time 29.14ms, mfu 12.51%\n",
            "iter 4420: loss 1.6404, time 29.22ms, mfu 12.53%\n",
            "iter 4430: loss 1.6698, time 29.22ms, mfu 12.55%\n",
            "iter 4440: loss 1.6542, time 29.09ms, mfu 12.58%\n",
            "iter 4450: loss 1.6574, time 29.08ms, mfu 12.60%\n",
            "iter 4460: loss 1.6603, time 29.14ms, mfu 12.62%\n",
            "iter 4470: loss 1.6507, time 29.39ms, mfu 12.62%\n",
            "iter 4480: loss 1.6489, time 29.23ms, mfu 12.63%\n",
            "iter 4490: loss 1.6367, time 29.24ms, mfu 12.64%\n",
            "step 4500: train loss 1.6030, val loss 1.6133\n",
            "saving checkpoint to out-arabicpoetry-char-default\n",
            "iter 4500: loss 1.6580, time 4835.00ms, mfu 11.39%\n",
            "iter 4510: loss 1.6611, time 29.22ms, mfu 11.52%\n",
            "iter 4520: loss 1.6494, time 29.29ms, mfu 11.64%\n",
            "iter 4530: loss 1.6688, time 29.13ms, mfu 11.76%\n",
            "iter 4540: loss 1.6365, time 29.04ms, mfu 11.86%\n",
            "iter 4550: loss 1.6373, time 29.22ms, mfu 11.95%\n",
            "iter 4560: loss 1.6610, time 29.17ms, mfu 12.03%\n",
            "iter 4570: loss 1.6522, time 29.14ms, mfu 12.11%\n",
            "iter 4580: loss 1.6752, time 29.11ms, mfu 12.17%\n",
            "iter 4590: loss 1.6619, time 29.20ms, mfu 12.23%\n",
            "iter 4600: loss 1.6432, time 28.61ms, mfu 12.31%\n",
            "iter 4610: loss 1.6554, time 29.13ms, mfu 12.36%\n",
            "iter 4620: loss 1.6454, time 29.08ms, mfu 12.40%\n",
            "iter 4630: loss 1.6407, time 29.21ms, mfu 12.44%\n",
            "iter 4640: loss 1.6350, time 29.16ms, mfu 12.47%\n",
            "iter 4650: loss 1.6535, time 29.37ms, mfu 12.49%\n",
            "iter 4660: loss 1.6598, time 29.30ms, mfu 12.51%\n",
            "iter 4670: loss 1.6380, time 29.10ms, mfu 12.54%\n",
            "iter 4680: loss 1.6426, time 29.45ms, mfu 12.55%\n",
            "iter 4690: loss 1.6523, time 29.31ms, mfu 12.57%\n",
            "iter 4700: loss 1.6781, time 29.16ms, mfu 12.59%\n",
            "iter 4710: loss 1.6415, time 29.02ms, mfu 12.61%\n",
            "iter 4720: loss 1.6471, time 28.99ms, mfu 12.63%\n",
            "iter 4730: loss 1.6237, time 29.14ms, mfu 12.65%\n",
            "iter 4740: loss 1.6224, time 29.26ms, mfu 12.66%\n",
            "step 4750: train loss 1.6003, val loss 1.6090\n",
            "saving checkpoint to out-arabicpoetry-char-default\n",
            "iter 4750: loss 1.6355, time 4846.86ms, mfu 11.40%\n",
            "iter 4760: loss 1.6599, time 28.96ms, mfu 11.54%\n",
            "iter 4770: loss 1.6452, time 28.93ms, mfu 11.68%\n",
            "iter 4780: loss 1.6761, time 28.92ms, mfu 11.80%\n",
            "iter 4790: loss 1.6474, time 29.18ms, mfu 11.89%\n",
            "iter 4800: loss 1.6804, time 29.60ms, mfu 11.96%\n",
            "iter 4810: loss 1.6661, time 29.39ms, mfu 12.03%\n",
            "iter 4820: loss 1.6671, time 29.14ms, mfu 12.11%\n",
            "iter 4830: loss 1.6516, time 29.09ms, mfu 12.17%\n",
            "iter 4840: loss 1.6619, time 28.90ms, mfu 12.25%\n",
            "iter 4850: loss 1.6765, time 29.22ms, mfu 12.30%\n",
            "iter 4860: loss 1.6485, time 28.92ms, mfu 12.35%\n",
            "iter 4870: loss 1.6464, time 29.11ms, mfu 12.40%\n",
            "iter 4880: loss 1.6302, time 29.00ms, mfu 12.44%\n",
            "iter 4890: loss 1.6615, time 29.09ms, mfu 12.48%\n",
            "iter 4900: loss 1.6477, time 29.43ms, mfu 12.49%\n",
            "iter 4910: loss 1.6464, time 29.07ms, mfu 12.53%\n",
            "iter 4920: loss 1.6416, time 29.40ms, mfu 12.54%\n",
            "iter 4930: loss 1.6680, time 29.13ms, mfu 12.56%\n",
            "iter 4940: loss 1.6541, time 29.20ms, mfu 12.58%\n",
            "iter 4950: loss 1.6175, time 29.09ms, mfu 12.60%\n",
            "iter 4960: loss 1.6550, time 29.02ms, mfu 12.63%\n",
            "iter 4970: loss 1.6528, time 29.22ms, mfu 12.64%\n",
            "iter 4980: loss 1.6538, time 29.12ms, mfu 12.65%\n",
            "iter 4990: loss 1.6381, time 29.13ms, mfu 12.66%\n",
            "step 5000: train loss 1.5961, val loss 1.6050\n",
            "saving checkpoint to out-arabicpoetry-char-default\n",
            "iter 5000: loss 1.6650, time 4859.78ms, mfu 11.41%\n"
          ]
        }
      ],
      "source": [
        "!python3 train.py config/train_arabicpoetry_char.py --out_dir=\"out-arabicpoetry-char-default\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dEyLfwsfGwDF"
      },
      "source": [
        "#### B. Using adjusted parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mc5nkvTIQGvt"
      },
      "source": [
        "We adjust the following parameters: batch size, number of layers, and number of attention heads."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tVvcCm8LfKP3",
        "outputId": "dd67a190-49b4-4021-dc7c-af13b7989d7a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overriding config with config/train_arabicpoetry_char.py:\n",
            "# train a miniature character-level arabicpoetry model\n",
            "\n",
            "out_dir = 'out-arabicpoetry-char'\n",
            "eval_interval = 250\n",
            "eval_iters = 200\n",
            "log_interval = 10 \n",
            "\n",
            "always_save_checkpoint = False\n",
            "\n",
            "wandb_log = False \n",
            "wandb_project = 'arabicpoetry-char'\n",
            "wandb_run_name = 'mini-gpt'\n",
            "\n",
            "dataset = 'arabicpoetry_char'\n",
            "gradient_accumulation_steps = 1\n",
            "batch_size = 64\n",
            "block_size = 256\n",
            "\n",
            "n_layer = 6\n",
            "n_head = 6\n",
            "n_embd = 384\n",
            "dropout = 0.2\n",
            "\n",
            "learning_rate = 1e-3 \n",
            "max_iters = 5000\n",
            "lr_decay_iters = 5000 \n",
            "min_lr = 1e-4 \n",
            "beta2 = 0.99 \n",
            "\n",
            "warmup_iters = 100 \n",
            "Overriding: out_dir = out-arabicpoetry-char-adjusted\n",
            "Overriding: batch_size = 256\n",
            "Overriding: n_layer = 12\n",
            "Overriding: n_head = 12\n",
            "tokens per iteration will be: 65,536\n",
            "found vocab_size = 38 (inside data/arabicpoetry_char/meta.pkl)\n",
            "Initializing a new model from scratch\n",
            "number of parameters: 21.26M\n",
            "num decayed parameter tensors: 50, with 21,346,560 parameters\n",
            "num non-decayed parameter tensors: 25, with 9,600 parameters\n",
            "using fused AdamW: True\n",
            "compiling the model... (takes a ~minute)\n",
            "step 0: train loss 3.7256, val loss 3.7272\n",
            "iter 0: loss 3.7126, time 77878.22ms, mfu -100.00%\n",
            "iter 10: loss 2.9183, time 248.72ms, mfu 11.97%\n",
            "iter 20: loss 2.7954, time 249.21ms, mfu 11.96%\n",
            "iter 30: loss 2.7258, time 248.50ms, mfu 11.97%\n",
            "iter 40: loss 2.7004, time 247.52ms, mfu 11.97%\n",
            "iter 50: loss 2.7005, time 247.18ms, mfu 11.98%\n",
            "iter 60: loss 2.6734, time 248.28ms, mfu 11.98%\n",
            "iter 70: loss 2.6689, time 249.45ms, mfu 11.98%\n",
            "iter 80: loss 2.6827, time 249.31ms, mfu 11.97%\n",
            "iter 90: loss 2.6705, time 247.70ms, mfu 11.98%\n",
            "iter 100: loss 2.6713, time 248.08ms, mfu 11.98%\n",
            "iter 110: loss 2.6749, time 248.45ms, mfu 11.98%\n",
            "iter 120: loss 2.6502, time 249.44ms, mfu 11.97%\n",
            "iter 130: loss 2.6371, time 249.65ms, mfu 11.97%\n",
            "iter 140: loss 2.6167, time 251.07ms, mfu 11.96%\n",
            "iter 150: loss 2.6671, time 248.19ms, mfu 11.96%\n",
            "iter 160: loss 2.6053, time 248.58ms, mfu 11.96%\n",
            "iter 170: loss 2.5645, time 248.53ms, mfu 11.96%\n",
            "iter 180: loss 2.4980, time 249.34ms, mfu 11.96%\n",
            "iter 190: loss 2.4604, time 250.83ms, mfu 11.95%\n",
            "iter 200: loss 2.4088, time 250.56ms, mfu 11.94%\n",
            "iter 210: loss 2.3875, time 249.03ms, mfu 11.95%\n",
            "iter 220: loss 2.3595, time 248.95ms, mfu 11.95%\n",
            "iter 230: loss 2.3259, time 247.83ms, mfu 11.95%\n",
            "iter 240: loss 2.2992, time 248.18ms, mfu 11.96%\n",
            "step 250: train loss 2.2150, val loss 2.2097\n",
            "saving checkpoint to out-arabicpoetry-char-adjusted\n",
            "iter 250: loss 2.2515, time 31584.44ms, mfu 10.77%\n",
            "iter 260: loss 2.2360, time 250.09ms, mfu 10.88%\n",
            "iter 270: loss 2.2171, time 250.93ms, mfu 10.98%\n",
            "iter 280: loss 2.1993, time 251.32ms, mfu 11.07%\n",
            "iter 290: loss 2.1679, time 252.72ms, mfu 11.14%\n",
            "iter 300: loss 2.2238, time 249.75ms, mfu 11.22%\n",
            "iter 310: loss 2.1630, time 249.70ms, mfu 11.29%\n",
            "iter 320: loss 2.1275, time 249.32ms, mfu 11.35%\n",
            "iter 330: loss 2.0990, time 251.30ms, mfu 11.40%\n",
            "iter 340: loss 2.0912, time 251.17ms, mfu 11.45%\n",
            "iter 350: loss 2.0660, time 457.31ms, mfu 10.95%\n",
            "iter 360: loss 2.0554, time 249.09ms, mfu 11.05%\n",
            "iter 370: loss 2.0438, time 249.05ms, mfu 11.14%\n",
            "iter 380: loss 2.0629, time 248.85ms, mfu 11.22%\n",
            "iter 390: loss 2.0329, time 248.84ms, mfu 11.30%\n",
            "iter 400: loss 2.0275, time 248.87ms, mfu 11.36%\n",
            "iter 410: loss 2.0019, time 251.50ms, mfu 11.41%\n",
            "iter 420: loss 1.9964, time 251.23ms, mfu 11.45%\n",
            "iter 430: loss 1.9741, time 251.40ms, mfu 11.49%\n",
            "iter 440: loss 1.9743, time 252.86ms, mfu 11.52%\n",
            "iter 450: loss 1.9698, time 251.80ms, mfu 11.55%\n",
            "iter 460: loss 1.9568, time 248.61ms, mfu 11.59%\n",
            "iter 470: loss 1.9462, time 249.23ms, mfu 11.63%\n",
            "iter 480: loss 1.9347, time 248.94ms, mfu 11.66%\n",
            "iter 490: loss 1.9442, time 248.87ms, mfu 11.69%\n",
            "step 500: train loss 1.8715, val loss 1.8691\n",
            "saving checkpoint to out-arabicpoetry-char-adjusted\n",
            "iter 500: loss 1.9240, time 31900.27ms, mfu 10.53%\n",
            "iter 510: loss 1.9193, time 252.73ms, mfu 10.66%\n",
            "iter 520: loss 1.9072, time 250.18ms, mfu 10.78%\n",
            "iter 530: loss 1.9136, time 249.17ms, mfu 10.90%\n",
            "iter 540: loss 1.8838, time 249.05ms, mfu 11.00%\n",
            "iter 550: loss 1.8800, time 248.96ms, mfu 11.10%\n",
            "iter 560: loss 1.8805, time 248.67ms, mfu 11.18%\n",
            "iter 570: loss 1.8664, time 248.97ms, mfu 11.26%\n",
            "iter 580: loss 1.8651, time 250.19ms, mfu 11.33%\n",
            "iter 590: loss 1.8411, time 250.69ms, mfu 11.38%\n",
            "iter 600: loss 1.8509, time 251.17ms, mfu 11.43%\n",
            "iter 610: loss 1.8288, time 251.40ms, mfu 11.47%\n",
            "iter 620: loss 1.8303, time 249.00ms, mfu 11.52%\n",
            "iter 630: loss 1.8372, time 248.81ms, mfu 11.56%\n",
            "iter 640: loss 1.8354, time 248.00ms, mfu 11.61%\n",
            "iter 650: loss 1.8235, time 248.89ms, mfu 11.64%\n",
            "iter 660: loss 1.8357, time 249.58ms, mfu 11.67%\n",
            "iter 670: loss 1.8090, time 249.36ms, mfu 11.70%\n",
            "iter 680: loss 1.8056, time 250.43ms, mfu 11.72%\n",
            "iter 690: loss 1.8066, time 251.06ms, mfu 11.73%\n",
            "iter 700: loss 1.7948, time 250.57ms, mfu 11.74%\n",
            "iter 710: loss 1.7952, time 248.55ms, mfu 11.77%\n",
            "iter 720: loss 1.7903, time 249.96ms, mfu 11.78%\n",
            "iter 730: loss 1.7971, time 251.28ms, mfu 11.79%\n",
            "iter 740: loss 1.7814, time 250.77ms, mfu 11.80%\n",
            "step 750: train loss 1.7443, val loss 1.7450\n",
            "saving checkpoint to out-arabicpoetry-char-adjusted\n",
            "iter 750: loss 1.7901, time 32085.21ms, mfu 10.63%\n",
            "iter 760: loss 1.7738, time 251.83ms, mfu 10.74%\n",
            "iter 770: loss 1.7843, time 251.26ms, mfu 10.86%\n",
            "iter 780: loss 1.7757, time 248.92ms, mfu 10.97%\n",
            "iter 790: loss 1.7722, time 248.80ms, mfu 11.07%\n",
            "iter 800: loss 1.7523, time 248.31ms, mfu 11.16%\n",
            "iter 810: loss 1.7596, time 248.98ms, mfu 11.24%\n",
            "iter 820: loss 1.7578, time 249.05ms, mfu 11.31%\n",
            "iter 830: loss 1.7473, time 249.80ms, mfu 11.37%\n",
            "iter 840: loss 1.7481, time 250.21ms, mfu 11.42%\n",
            "iter 850: loss 1.7408, time 252.65ms, mfu 11.46%\n",
            "iter 860: loss 1.7379, time 252.52ms, mfu 11.49%\n",
            "iter 870: loss 1.7557, time 251.08ms, mfu 11.53%\n",
            "iter 880: loss 1.7271, time 249.08ms, mfu 11.57%\n",
            "iter 890: loss 1.7340, time 248.49ms, mfu 11.61%\n",
            "iter 900: loss 1.7430, time 249.16ms, mfu 11.64%\n",
            "iter 910: loss 1.7332, time 249.34ms, mfu 11.67%\n",
            "iter 920: loss 1.7423, time 249.74ms, mfu 11.70%\n",
            "iter 930: loss 1.7220, time 250.97ms, mfu 11.71%\n",
            "iter 940: loss 1.7211, time 251.41ms, mfu 11.73%\n",
            "iter 950: loss 1.7261, time 250.53ms, mfu 11.74%\n",
            "iter 960: loss 1.7232, time 249.16ms, mfu 11.76%\n",
            "iter 970: loss 1.7162, time 249.40ms, mfu 11.78%\n",
            "iter 980: loss 1.7209, time 248.95ms, mfu 11.80%\n",
            "iter 990: loss 1.7073, time 249.06ms, mfu 11.81%\n",
            "step 1000: train loss 1.6659, val loss 1.6716\n",
            "saving checkpoint to out-arabicpoetry-char-adjusted\n",
            "iter 1000: loss 1.6982, time 31861.43ms, mfu 10.64%\n",
            "iter 1010: loss 1.6984, time 250.61ms, mfu 10.76%\n",
            "iter 1020: loss 1.7003, time 249.45ms, mfu 10.88%\n",
            "iter 1030: loss 1.7089, time 249.45ms, mfu 10.99%\n",
            "iter 1040: loss 1.6875, time 248.54ms, mfu 11.09%\n",
            "iter 1050: loss 1.6942, time 248.42ms, mfu 11.17%\n",
            "iter 1060: loss 1.6926, time 250.51ms, mfu 11.25%\n",
            "iter 1070: loss 1.6839, time 251.07ms, mfu 11.31%\n",
            "iter 1080: loss 1.6789, time 250.37ms, mfu 11.36%\n",
            "iter 1090: loss 1.6752, time 249.64ms, mfu 11.42%\n",
            "iter 1100: loss 1.6860, time 248.86ms, mfu 11.47%\n",
            "iter 1110: loss 1.6754, time 248.05ms, mfu 11.53%\n",
            "iter 1120: loss 1.6757, time 248.13ms, mfu 11.57%\n",
            "iter 1130: loss 1.6795, time 247.91ms, mfu 11.62%\n",
            "iter 1140: loss 1.6684, time 250.70ms, mfu 11.64%\n",
            "iter 1150: loss 1.6584, time 250.12ms, mfu 11.67%\n",
            "iter 1160: loss 1.6674, time 251.42ms, mfu 11.69%\n",
            "iter 1170: loss 1.6623, time 251.11ms, mfu 11.70%\n",
            "iter 1180: loss 1.6662, time 249.29ms, mfu 11.73%\n",
            "iter 1190: loss 1.6672, time 249.08ms, mfu 11.75%\n",
            "iter 1200: loss 1.6496, time 173.18ms, mfu 12.29%\n",
            "iter 1210: loss 1.6618, time 249.86ms, mfu 12.25%\n",
            "iter 1220: loss 1.6609, time 249.17ms, mfu 12.22%\n",
            "iter 1230: loss 1.6560, time 251.32ms, mfu 12.19%\n",
            "iter 1240: loss 1.6475, time 250.51ms, mfu 12.16%\n",
            "step 1250: train loss 1.6091, val loss 1.6183\n",
            "saving checkpoint to out-arabicpoetry-char-adjusted\n",
            "iter 1250: loss 1.6387, time 31907.25ms, mfu 10.95%\n",
            "iter 1260: loss 1.6422, time 249.57ms, mfu 11.05%\n",
            "iter 1270: loss 1.6415, time 250.28ms, mfu 11.13%\n",
            "iter 1280: loss 1.6325, time 251.14ms, mfu 11.20%\n",
            "iter 1290: loss 1.6309, time 251.79ms, mfu 11.27%\n",
            "iter 1300: loss 1.6323, time 251.39ms, mfu 11.32%\n",
            "iter 1310: loss 1.6348, time 248.36ms, mfu 11.39%\n",
            "iter 1320: loss 1.6350, time 248.09ms, mfu 11.45%\n",
            "iter 1330: loss 1.6397, time 248.53ms, mfu 11.50%\n",
            "iter 1340: loss 1.6433, time 248.38ms, mfu 11.55%\n",
            "iter 1350: loss 1.6297, time 249.20ms, mfu 11.59%\n",
            "iter 1360: loss 1.6229, time 250.28ms, mfu 11.62%\n",
            "iter 1370: loss 1.6224, time 251.84ms, mfu 11.64%\n",
            "iter 1380: loss 1.6177, time 251.81ms, mfu 11.66%\n",
            "iter 1390: loss 1.6303, time 250.80ms, mfu 11.68%\n",
            "iter 1400: loss 1.6308, time 249.77ms, mfu 11.70%\n",
            "iter 1410: loss 1.6302, time 250.08ms, mfu 11.72%\n",
            "iter 1420: loss 1.6101, time 249.28ms, mfu 11.74%\n",
            "iter 1430: loss 1.5995, time 250.03ms, mfu 11.76%\n",
            "iter 1440: loss 1.6102, time 251.19ms, mfu 11.77%\n",
            "iter 1450: loss 1.6169, time 251.99ms, mfu 11.77%\n",
            "iter 1460: loss 1.6062, time 250.14ms, mfu 11.79%\n",
            "iter 1470: loss 1.5946, time 249.64ms, mfu 11.80%\n",
            "iter 1480: loss 1.5846, time 249.25ms, mfu 11.81%\n",
            "iter 1490: loss 1.6214, time 249.35ms, mfu 11.83%\n",
            "step 1500: train loss 1.5523, val loss 1.5654\n",
            "saving checkpoint to out-arabicpoetry-char-adjusted\n",
            "iter 1500: loss 1.6163, time 32073.11ms, mfu 10.65%\n",
            "iter 1510: loss 1.6057, time 250.42ms, mfu 10.78%\n",
            "iter 1520: loss 1.5923, time 250.78ms, mfu 10.89%\n",
            "iter 1530: loss 1.6003, time 252.00ms, mfu 10.98%\n",
            "iter 1540: loss 1.5896, time 250.46ms, mfu 11.07%\n",
            "iter 1550: loss 1.5856, time 250.85ms, mfu 11.15%\n",
            "iter 1560: loss 1.6105, time 248.24ms, mfu 11.23%\n",
            "iter 1570: loss 1.5885, time 249.34ms, mfu 11.30%\n",
            "iter 1580: loss 1.5932, time 250.32ms, mfu 11.36%\n",
            "iter 1590: loss 1.5797, time 249.74ms, mfu 11.42%\n",
            "iter 1600: loss 1.5873, time 250.39ms, mfu 11.46%\n",
            "iter 1610: loss 1.5950, time 250.40ms, mfu 11.51%\n",
            "iter 1620: loss 1.5860, time 251.59ms, mfu 11.54%\n",
            "iter 1630: loss 1.5679, time 252.15ms, mfu 11.57%\n",
            "iter 1640: loss 1.5748, time 248.60ms, mfu 11.61%\n",
            "iter 1650: loss 1.5651, time 248.86ms, mfu 11.64%\n",
            "iter 1660: loss 1.5824, time 248.09ms, mfu 11.68%\n",
            "iter 1670: loss 1.5767, time 250.39ms, mfu 11.70%\n",
            "iter 1680: loss 1.5768, time 248.43ms, mfu 11.73%\n",
            "iter 1690: loss 1.5660, time 249.81ms, mfu 11.75%\n",
            "iter 1700: loss 1.5668, time 250.19ms, mfu 11.76%\n",
            "iter 1710: loss 1.5643, time 251.05ms, mfu 11.77%\n",
            "iter 1720: loss 1.5715, time 251.51ms, mfu 11.78%\n",
            "iter 1730: loss 1.5533, time 251.93ms, mfu 11.78%\n",
            "iter 1740: loss 1.5644, time 250.77ms, mfu 11.79%\n",
            "step 1750: train loss 1.5131, val loss 1.5318\n",
            "saving checkpoint to out-arabicpoetry-char-adjusted\n",
            "iter 1750: loss 1.5711, time 31940.04ms, mfu 10.62%\n",
            "iter 1760: loss 1.5445, time 249.22ms, mfu 10.75%\n",
            "iter 1770: loss 1.5654, time 249.06ms, mfu 10.87%\n",
            "iter 1780: loss 1.5513, time 250.03ms, mfu 10.98%\n",
            "iter 1790: loss 1.5467, time 250.70ms, mfu 11.07%\n",
            "iter 1800: loss 1.5521, time 251.36ms, mfu 11.14%\n",
            "iter 1810: loss 1.5462, time 250.64ms, mfu 11.22%\n",
            "iter 1820: loss 1.5314, time 250.43ms, mfu 11.28%\n",
            "iter 1830: loss 1.5516, time 248.88ms, mfu 11.35%\n",
            "iter 1840: loss 1.5470, time 248.85ms, mfu 11.41%\n",
            "iter 1850: loss 1.5581, time 248.37ms, mfu 11.47%\n",
            "iter 1860: loss 1.5370, time 248.14ms, mfu 11.52%\n",
            "iter 1870: loss 1.5442, time 249.06ms, mfu 11.56%\n",
            "iter 1880: loss 1.5458, time 248.07ms, mfu 11.61%\n",
            "iter 1890: loss 1.5322, time 250.62ms, mfu 11.63%\n",
            "iter 1900: loss 1.5382, time 251.27ms, mfu 11.66%\n",
            "iter 1910: loss 1.5428, time 250.54ms, mfu 11.68%\n",
            "iter 1920: loss 1.5258, time 250.67ms, mfu 11.70%\n",
            "iter 1930: loss 1.5321, time 248.99ms, mfu 11.72%\n",
            "iter 1940: loss 1.5303, time 249.31ms, mfu 11.75%\n",
            "iter 1950: loss 1.5235, time 249.24ms, mfu 11.76%\n",
            "iter 1960: loss 1.5364, time 250.29ms, mfu 11.78%\n",
            "iter 1970: loss 1.5349, time 252.30ms, mfu 11.78%\n",
            "iter 1980: loss 1.5343, time 251.38ms, mfu 11.79%\n",
            "iter 1990: loss 1.5274, time 251.22ms, mfu 11.79%\n",
            "step 2000: train loss 1.4796, val loss 1.5030\n",
            "saving checkpoint to out-arabicpoetry-char-adjusted\n",
            "iter 2000: loss 1.5301, time 32097.45ms, mfu 10.62%\n",
            "iter 2010: loss 1.5065, time 248.63ms, mfu 10.76%\n",
            "iter 2020: loss 1.5225, time 248.26ms, mfu 10.88%\n",
            "iter 2030: loss 1.5291, time 249.03ms, mfu 10.99%\n",
            "iter 2040: loss 1.5148, time 248.06ms, mfu 11.09%\n",
            "iter 2050: loss 1.5107, time 249.31ms, mfu 11.17%\n",
            "iter 2060: loss 1.5202, time 250.79ms, mfu 11.24%\n",
            "iter 2070: loss 1.5070, time 250.84ms, mfu 11.31%\n",
            "iter 2080: loss 1.5110, time 250.37ms, mfu 11.36%\n",
            "iter 2090: loss 1.5120, time 250.06ms, mfu 11.42%\n",
            "iter 2100: loss 1.5295, time 249.77ms, mfu 11.47%\n",
            "iter 2110: loss 1.5092, time 250.24ms, mfu 11.51%\n",
            "iter 2120: loss 1.5082, time 249.38ms, mfu 11.55%\n",
            "iter 2130: loss 1.5140, time 250.58ms, mfu 11.59%\n",
            "iter 2140: loss 1.5011, time 250.94ms, mfu 11.61%\n",
            "iter 2150: loss 1.5029, time 251.04ms, mfu 11.64%\n",
            "iter 2160: loss 1.5086, time 251.88ms, mfu 11.66%\n",
            "iter 2170: loss 1.5088, time 252.30ms, mfu 11.67%\n",
            "iter 2180: loss 1.5245, time 248.71ms, mfu 11.70%\n",
            "iter 2190: loss 1.5033, time 249.05ms, mfu 11.72%\n",
            "iter 2200: loss 1.5128, time 249.04ms, mfu 11.75%\n",
            "iter 2210: loss 1.5002, time 248.74ms, mfu 11.77%\n",
            "iter 2220: loss 1.5070, time 249.28ms, mfu 11.79%\n",
            "iter 2230: loss 1.5062, time 250.37ms, mfu 11.80%\n",
            "iter 2240: loss 1.5031, time 251.04ms, mfu 11.80%\n",
            "step 2250: train loss 1.4541, val loss 1.4790\n",
            "saving checkpoint to out-arabicpoetry-char-adjusted\n",
            "iter 2250: loss 1.5004, time 31869.34ms, mfu 10.63%\n",
            "iter 2260: loss 1.4974, time 249.82ms, mfu 10.76%\n",
            "iter 2270: loss 1.4982, time 249.40ms, mfu 10.88%\n",
            "iter 2280: loss 1.4870, time 250.13ms, mfu 10.98%\n",
            "iter 2290: loss 1.4826, time 251.13ms, mfu 11.07%\n",
            "iter 2300: loss 1.5129, time 250.77ms, mfu 11.15%\n",
            "iter 2310: loss 1.4884, time 251.34ms, mfu 11.22%\n",
            "iter 2320: loss 1.4833, time 251.86ms, mfu 11.28%\n",
            "iter 2330: loss 1.4783, time 248.39ms, mfu 11.35%\n",
            "iter 2340: loss 1.4787, time 248.90ms, mfu 11.41%\n",
            "iter 2350: loss 1.5004, time 329.08ms, mfu 11.17%\n",
            "iter 2360: loss 1.4884, time 248.51ms, mfu 11.25%\n",
            "iter 2370: loss 1.4992, time 250.11ms, mfu 11.32%\n",
            "iter 2380: loss 1.4898, time 250.43ms, mfu 11.37%\n",
            "iter 2390: loss 1.4862, time 251.15ms, mfu 11.42%\n",
            "iter 2400: loss 1.4900, time 251.39ms, mfu 11.46%\n",
            "iter 2410: loss 1.4862, time 251.90ms, mfu 11.50%\n",
            "iter 2420: loss 1.4796, time 252.19ms, mfu 11.53%\n",
            "iter 2430: loss 1.4693, time 249.53ms, mfu 11.57%\n",
            "iter 2440: loss 1.4812, time 249.00ms, mfu 11.61%\n",
            "iter 2450: loss 1.4830, time 249.86ms, mfu 11.64%\n",
            "iter 2460: loss 1.4840, time 249.63ms, mfu 11.67%\n",
            "iter 2470: loss 1.4794, time 247.62ms, mfu 11.70%\n",
            "iter 2480: loss 1.4593, time 248.70ms, mfu 11.73%\n",
            "iter 2490: loss 1.4713, time 249.67ms, mfu 11.75%\n",
            "step 2500: train loss 1.4317, val loss 1.4588\n",
            "saving checkpoint to out-arabicpoetry-char-adjusted\n",
            "iter 2500: loss 1.4783, time 31788.71ms, mfu 10.58%\n",
            "iter 2510: loss 1.4726, time 251.17ms, mfu 10.71%\n",
            "iter 2520: loss 1.4674, time 252.43ms, mfu 10.82%\n",
            "iter 2530: loss 1.4821, time 250.95ms, mfu 10.92%\n",
            "iter 2540: loss 1.4522, time 250.24ms, mfu 11.02%\n",
            "iter 2550: loss 1.4667, time 249.21ms, mfu 11.11%\n",
            "iter 2560: loss 1.4639, time 248.85ms, mfu 11.20%\n",
            "iter 2570: loss 1.4692, time 249.51ms, mfu 11.27%\n",
            "iter 2580: loss 1.4813, time 249.42ms, mfu 11.34%\n",
            "iter 2590: loss 1.4598, time 251.55ms, mfu 11.39%\n",
            "iter 2600: loss 1.4781, time 251.27ms, mfu 11.43%\n",
            "iter 2610: loss 1.4442, time 250.71ms, mfu 11.48%\n",
            "iter 2620: loss 1.4767, time 251.12ms, mfu 11.51%\n",
            "iter 2630: loss 1.4697, time 250.65ms, mfu 11.55%\n",
            "iter 2640: loss 1.4540, time 250.71ms, mfu 11.58%\n",
            "iter 2650: loss 1.4605, time 250.15ms, mfu 11.61%\n",
            "iter 2660: loss 1.4687, time 249.14ms, mfu 11.65%\n",
            "iter 2670: loss 1.4669, time 249.62ms, mfu 11.67%\n",
            "iter 2680: loss 1.4678, time 249.54ms, mfu 11.70%\n",
            "iter 2690: loss 1.4524, time 249.68ms, mfu 11.72%\n",
            "iter 2700: loss 1.4658, time 250.93ms, mfu 11.74%\n",
            "iter 2710: loss 1.4640, time 251.60ms, mfu 11.75%\n",
            "iter 2720: loss 1.4529, time 250.83ms, mfu 11.76%\n",
            "iter 2730: loss 1.4605, time 251.69ms, mfu 11.76%\n",
            "iter 2740: loss 1.4513, time 251.70ms, mfu 11.77%\n",
            "step 2750: train loss 1.4121, val loss 1.4418\n",
            "saving checkpoint to out-arabicpoetry-char-adjusted\n",
            "iter 2750: loss 1.4675, time 32151.14ms, mfu 10.60%\n",
            "iter 2760: loss 1.4699, time 251.25ms, mfu 10.73%\n",
            "iter 2770: loss 1.4592, time 250.32ms, mfu 10.84%\n",
            "iter 2780: loss 1.4587, time 251.30ms, mfu 10.94%\n",
            "iter 2790: loss 1.4570, time 250.21ms, mfu 11.04%\n",
            "iter 2800: loss 1.4680, time 249.72ms, mfu 11.13%\n",
            "iter 2810: loss 1.4528, time 248.26ms, mfu 11.21%\n",
            "iter 2820: loss 1.4469, time 248.58ms, mfu 11.29%\n",
            "iter 2830: loss 1.4523, time 250.73ms, mfu 11.35%\n",
            "iter 2840: loss 1.4441, time 250.76ms, mfu 11.40%\n",
            "iter 2850: loss 1.4430, time 249.24ms, mfu 11.45%\n",
            "iter 2860: loss 1.4312, time 248.73ms, mfu 11.51%\n",
            "iter 2870: loss 1.4534, time 249.21ms, mfu 11.55%\n",
            "iter 2880: loss 1.4474, time 248.45ms, mfu 11.59%\n",
            "iter 2890: loss 1.4469, time 248.95ms, mfu 11.63%\n",
            "iter 2900: loss 1.4571, time 250.04ms, mfu 11.66%\n",
            "iter 2910: loss 1.4393, time 251.28ms, mfu 11.68%\n",
            "iter 2920: loss 1.4332, time 251.78ms, mfu 11.69%\n",
            "iter 2930: loss 1.4477, time 250.62ms, mfu 11.71%\n",
            "iter 2940: loss 1.4354, time 250.77ms, mfu 11.72%\n",
            "iter 2950: loss 1.4322, time 249.62ms, mfu 11.74%\n",
            "iter 2960: loss 1.4494, time 249.11ms, mfu 11.76%\n",
            "iter 2970: loss 1.4436, time 249.13ms, mfu 11.78%\n",
            "iter 2980: loss 1.4395, time 249.07ms, mfu 11.80%\n",
            "iter 2990: loss 1.4369, time 248.78ms, mfu 11.82%\n",
            "step 3000: train loss 1.3948, val loss 1.4306\n",
            "saving checkpoint to out-arabicpoetry-char-adjusted\n",
            "iter 3000: loss 1.4483, time 31906.38ms, mfu 10.64%\n",
            "iter 3010: loss 1.4397, time 249.84ms, mfu 10.77%\n",
            "iter 3020: loss 1.4382, time 249.12ms, mfu 10.89%\n",
            "iter 3030: loss 1.4468, time 248.72ms, mfu 11.00%\n",
            "iter 3040: loss 1.4317, time 250.05ms, mfu 11.09%\n",
            "iter 3050: loss 1.4427, time 250.13ms, mfu 11.17%\n",
            "iter 3060: loss 1.4402, time 250.35ms, mfu 11.24%\n",
            "iter 3070: loss 1.4348, time 250.84ms, mfu 11.30%\n",
            "iter 3080: loss 1.4395, time 249.28ms, mfu 11.37%\n",
            "iter 3090: loss 1.4397, time 250.22ms, mfu 11.42%\n",
            "iter 3100: loss 1.4343, time 251.36ms, mfu 11.46%\n",
            "iter 3110: loss 1.4344, time 250.10ms, mfu 11.51%\n",
            "iter 3120: loss 1.4266, time 249.40ms, mfu 11.55%\n",
            "iter 3130: loss 1.4407, time 250.19ms, mfu 11.58%\n",
            "iter 3140: loss 1.4369, time 248.92ms, mfu 11.62%\n",
            "iter 3150: loss 1.4322, time 249.85ms, mfu 11.65%\n",
            "iter 3160: loss 1.4361, time 249.43ms, mfu 11.68%\n",
            "iter 3170: loss 1.4279, time 248.85ms, mfu 11.71%\n",
            "iter 3180: loss 1.4308, time 249.31ms, mfu 11.73%\n",
            "iter 3190: loss 1.4401, time 250.63ms, mfu 11.74%\n",
            "iter 3200: loss 1.4241, time 167.33ms, mfu 12.35%\n",
            "iter 3210: loss 1.4221, time 252.17ms, mfu 12.29%\n",
            "iter 3220: loss 1.4254, time 251.53ms, mfu 12.25%\n",
            "iter 3230: loss 1.4289, time 250.22ms, mfu 12.21%\n",
            "iter 3240: loss 1.4246, time 249.56ms, mfu 12.18%\n",
            "step 3250: train loss 1.3833, val loss 1.4225\n",
            "saving checkpoint to out-arabicpoetry-char-adjusted\n",
            "iter 3250: loss 1.4226, time 31951.28ms, mfu 10.98%\n",
            "iter 3260: loss 1.4286, time 249.59ms, mfu 11.07%\n",
            "iter 3270: loss 1.4197, time 248.68ms, mfu 11.16%\n",
            "iter 3280: loss 1.4323, time 249.80ms, mfu 11.24%\n",
            "iter 3290: loss 1.4333, time 250.41ms, mfu 11.30%\n",
            "iter 3300: loss 1.4173, time 250.60ms, mfu 11.36%\n",
            "iter 3310: loss 1.4192, time 251.21ms, mfu 11.41%\n",
            "iter 3320: loss 1.4178, time 251.24ms, mfu 11.45%\n",
            "iter 3330: loss 1.4192, time 250.16ms, mfu 11.50%\n",
            "iter 3340: loss 1.4166, time 252.05ms, mfu 11.53%\n",
            "iter 3350: loss 1.4358, time 251.80ms, mfu 11.56%\n",
            "iter 3360: loss 1.4090, time 248.77ms, mfu 11.60%\n",
            "iter 3370: loss 1.4103, time 249.37ms, mfu 11.63%\n",
            "iter 3380: loss 1.4089, time 250.14ms, mfu 11.66%\n",
            "iter 3390: loss 1.4235, time 250.30ms, mfu 11.68%\n",
            "iter 3400: loss 1.4229, time 250.66ms, mfu 11.70%\n",
            "iter 3410: loss 1.4125, time 251.97ms, mfu 11.71%\n",
            "iter 3420: loss 1.4306, time 251.60ms, mfu 11.72%\n",
            "iter 3430: loss 1.4184, time 251.89ms, mfu 11.73%\n",
            "iter 3440: loss 1.4160, time 250.10ms, mfu 11.75%\n",
            "iter 3450: loss 1.4159, time 250.69ms, mfu 11.76%\n",
            "iter 3460: loss 1.4259, time 249.49ms, mfu 11.78%\n",
            "iter 3470: loss 1.4025, time 248.27ms, mfu 11.80%\n",
            "iter 3480: loss 1.4209, time 248.98ms, mfu 11.82%\n",
            "iter 3490: loss 1.4010, time 248.87ms, mfu 11.83%\n",
            "step 3500: train loss 1.3718, val loss 1.4129\n",
            "saving checkpoint to out-arabicpoetry-char-adjusted\n",
            "iter 3500: loss 1.4165, time 32034.61ms, mfu 10.66%\n",
            "iter 3510: loss 1.4209, time 251.96ms, mfu 10.77%\n",
            "iter 3520: loss 1.4066, time 253.63ms, mfu 10.87%\n",
            "iter 3530: loss 1.3990, time 249.96ms, mfu 10.97%\n",
            "iter 3540: loss 1.4182, time 249.37ms, mfu 11.07%\n",
            "iter 3550: loss 1.4129, time 248.80ms, mfu 11.16%\n",
            "iter 3560: loss 1.4170, time 249.52ms, mfu 11.24%\n",
            "iter 3570: loss 1.4231, time 250.02ms, mfu 11.30%\n",
            "iter 3580: loss 1.4203, time 250.22ms, mfu 11.36%\n",
            "iter 3590: loss 1.4139, time 250.73ms, mfu 11.41%\n",
            "iter 3600: loss 1.4026, time 251.17ms, mfu 11.46%\n",
            "iter 3610: loss 1.4099, time 251.41ms, mfu 11.49%\n",
            "iter 3620: loss 1.4247, time 252.58ms, mfu 11.52%\n",
            "iter 3630: loss 1.4163, time 251.55ms, mfu 11.55%\n",
            "iter 3640: loss 1.4043, time 251.79ms, mfu 11.58%\n",
            "iter 3650: loss 1.4058, time 252.87ms, mfu 11.60%\n",
            "iter 3660: loss 1.4116, time 250.00ms, mfu 11.63%\n",
            "iter 3670: loss 1.4125, time 249.34ms, mfu 11.66%\n",
            "iter 3680: loss 1.3966, time 250.10ms, mfu 11.69%\n",
            "iter 3690: loss 1.3998, time 249.05ms, mfu 11.71%\n",
            "iter 3700: loss 1.4099, time 249.73ms, mfu 11.73%\n",
            "iter 3710: loss 1.4053, time 249.33ms, mfu 11.75%\n",
            "iter 3720: loss 1.3930, time 250.42ms, mfu 11.77%\n",
            "iter 3730: loss 1.4060, time 250.18ms, mfu 11.78%\n",
            "iter 3740: loss 1.4042, time 251.39ms, mfu 11.79%\n",
            "step 3750: train loss 1.3610, val loss 1.4046\n",
            "saving checkpoint to out-arabicpoetry-char-adjusted\n",
            "iter 3750: loss 1.3936, time 31792.34ms, mfu 10.62%\n",
            "iter 3760: loss 1.3961, time 251.12ms, mfu 10.74%\n",
            "iter 3770: loss 1.4086, time 251.10ms, mfu 10.85%\n",
            "iter 3780: loss 1.4021, time 249.41ms, mfu 10.96%\n",
            "iter 3790: loss 1.4116, time 249.70ms, mfu 11.06%\n",
            "iter 3800: loss 1.4057, time 248.05ms, mfu 11.15%\n",
            "iter 3810: loss 1.4124, time 248.88ms, mfu 11.23%\n",
            "iter 3820: loss 1.4035, time 250.93ms, mfu 11.29%\n",
            "iter 3830: loss 1.3868, time 251.10ms, mfu 11.35%\n",
            "iter 3840: loss 1.4086, time 251.61ms, mfu 11.40%\n",
            "iter 3850: loss 1.3930, time 250.73ms, mfu 11.45%\n",
            "iter 3860: loss 1.3857, time 251.86ms, mfu 11.48%\n",
            "iter 3870: loss 1.3978, time 251.68ms, mfu 11.52%\n",
            "iter 3880: loss 1.3985, time 250.41ms, mfu 11.55%\n",
            "iter 3890: loss 1.3942, time 249.38ms, mfu 11.59%\n",
            "iter 3900: loss 1.4002, time 250.15ms, mfu 11.62%\n",
            "iter 3910: loss 1.3985, time 249.35ms, mfu 11.65%\n",
            "iter 3920: loss 1.4032, time 249.49ms, mfu 11.68%\n",
            "iter 3930: loss 1.3872, time 249.66ms, mfu 11.71%\n",
            "iter 3940: loss 1.3996, time 251.57ms, mfu 11.72%\n",
            "iter 3950: loss 1.4025, time 251.98ms, mfu 11.73%\n",
            "iter 3960: loss 1.4125, time 251.97ms, mfu 11.74%\n",
            "iter 3970: loss 1.3928, time 249.82ms, mfu 11.75%\n",
            "iter 3980: loss 1.4035, time 249.02ms, mfu 11.77%\n",
            "iter 3990: loss 1.4020, time 249.02ms, mfu 11.79%\n",
            "step 4000: train loss 1.3530, val loss 1.3985\n",
            "saving checkpoint to out-arabicpoetry-char-adjusted\n",
            "iter 4000: loss 1.3910, time 32122.87ms, mfu 10.62%\n",
            "iter 4010: loss 1.3841, time 248.32ms, mfu 10.76%\n",
            "iter 4020: loss 1.4095, time 248.67ms, mfu 10.88%\n",
            "iter 4030: loss 1.3917, time 249.68ms, mfu 10.98%\n",
            "iter 4040: loss 1.4122, time 248.95ms, mfu 11.08%\n",
            "iter 4050: loss 1.4043, time 250.71ms, mfu 11.16%\n",
            "iter 4060: loss 1.3987, time 252.51ms, mfu 11.22%\n",
            "iter 4070: loss 1.3861, time 251.19ms, mfu 11.29%\n",
            "iter 4080: loss 1.3955, time 250.68ms, mfu 11.34%\n",
            "iter 4090: loss 1.3870, time 249.59ms, mfu 11.40%\n",
            "iter 4100: loss 1.3737, time 248.82ms, mfu 11.46%\n",
            "iter 4110: loss 1.3791, time 249.19ms, mfu 11.51%\n",
            "iter 4120: loss 1.3933, time 249.84ms, mfu 11.55%\n",
            "iter 4130: loss 1.3873, time 249.86ms, mfu 11.58%\n",
            "iter 4140: loss 1.3756, time 249.72ms, mfu 11.62%\n",
            "iter 4150: loss 1.3868, time 250.31ms, mfu 11.65%\n",
            "iter 4160: loss 1.4129, time 250.48ms, mfu 11.67%\n",
            "iter 4170: loss 1.3897, time 251.14ms, mfu 11.69%\n",
            "iter 4180: loss 1.3840, time 250.47ms, mfu 11.71%\n",
            "iter 4190: loss 1.3842, time 250.59ms, mfu 11.72%\n",
            "iter 4200: loss 1.3926, time 252.21ms, mfu 11.73%\n",
            "iter 4210: loss 1.3954, time 250.96ms, mfu 11.74%\n",
            "iter 4220: loss 1.3684, time 251.47ms, mfu 11.75%\n",
            "iter 4230: loss 1.3910, time 249.61ms, mfu 11.77%\n",
            "iter 4240: loss 1.3786, time 249.31ms, mfu 11.79%\n",
            "step 4250: train loss 1.3439, val loss 1.3920\n",
            "saving checkpoint to out-arabicpoetry-char-adjusted\n",
            "iter 4250: loss 1.3887, time 31754.35ms, mfu 10.62%\n",
            "iter 4260: loss 1.3877, time 249.91ms, mfu 10.75%\n",
            "iter 4270: loss 1.3894, time 250.86ms, mfu 10.86%\n",
            "iter 4280: loss 1.3721, time 251.88ms, mfu 10.95%\n",
            "iter 4290: loss 1.3823, time 251.68ms, mfu 11.04%\n",
            "iter 4300: loss 1.3932, time 252.27ms, mfu 11.12%\n",
            "iter 4310: loss 1.3811, time 252.23ms, mfu 11.19%\n",
            "iter 4320: loss 1.3816, time 252.45ms, mfu 11.25%\n",
            "iter 4330: loss 1.3719, time 249.48ms, mfu 11.31%\n",
            "iter 4340: loss 1.3892, time 249.52ms, mfu 11.38%\n",
            "iter 4350: loss 1.3901, time 333.11ms, mfu 11.13%\n",
            "iter 4360: loss 1.3908, time 249.67ms, mfu 11.21%\n",
            "iter 4370: loss 1.3926, time 249.84ms, mfu 11.28%\n",
            "iter 4380: loss 1.3965, time 250.24ms, mfu 11.34%\n",
            "iter 4390: loss 1.3820, time 249.07ms, mfu 11.40%\n",
            "iter 4400: loss 1.3940, time 249.29ms, mfu 11.46%\n",
            "iter 4410: loss 1.3831, time 249.33ms, mfu 11.51%\n",
            "iter 4420: loss 1.3853, time 250.21ms, mfu 11.54%\n",
            "iter 4430: loss 1.3877, time 250.97ms, mfu 11.58%\n",
            "iter 4440: loss 1.3942, time 250.73ms, mfu 11.61%\n",
            "iter 4450: loss 1.3870, time 250.75ms, mfu 11.63%\n",
            "iter 4460: loss 1.3792, time 252.94ms, mfu 11.65%\n",
            "iter 4470: loss 1.3900, time 251.59ms, mfu 11.66%\n",
            "iter 4480: loss 1.3763, time 250.27ms, mfu 11.69%\n",
            "iter 4490: loss 1.3869, time 249.65ms, mfu 11.71%\n",
            "step 4500: train loss 1.3372, val loss 1.3892\n",
            "saving checkpoint to out-arabicpoetry-char-adjusted\n",
            "iter 4500: loss 1.3767, time 31854.46ms, mfu 10.55%\n",
            "iter 4510: loss 1.3859, time 250.74ms, mfu 10.68%\n",
            "iter 4520: loss 1.3949, time 251.58ms, mfu 10.80%\n",
            "iter 4530: loss 1.3928, time 251.94ms, mfu 10.90%\n",
            "iter 4540: loss 1.3670, time 248.69ms, mfu 11.00%\n",
            "iter 4550: loss 1.3803, time 249.06ms, mfu 11.10%\n",
            "iter 4560: loss 1.3843, time 248.86ms, mfu 11.19%\n",
            "iter 4570: loss 1.3740, time 249.09ms, mfu 11.26%\n",
            "iter 4580: loss 1.3759, time 248.76ms, mfu 11.33%\n",
            "iter 4590: loss 1.3710, time 249.34ms, mfu 11.39%\n",
            "iter 4600: loss 1.3783, time 250.96ms, mfu 11.44%\n",
            "iter 4610: loss 1.3810, time 252.15ms, mfu 11.48%\n",
            "iter 4620: loss 1.3768, time 250.82ms, mfu 11.52%\n",
            "iter 4630: loss 1.3742, time 249.63ms, mfu 11.56%\n",
            "iter 4640: loss 1.3824, time 249.02ms, mfu 11.60%\n",
            "iter 4650: loss 1.3754, time 249.16ms, mfu 11.63%\n",
            "iter 4660: loss 1.3666, time 250.53ms, mfu 11.66%\n",
            "iter 4670: loss 1.3843, time 251.82ms, mfu 11.67%\n",
            "iter 4680: loss 1.3678, time 251.59ms, mfu 11.69%\n",
            "iter 4690: loss 1.3861, time 251.12ms, mfu 11.70%\n",
            "iter 4700: loss 1.3810, time 251.44ms, mfu 11.72%\n",
            "iter 4710: loss 1.3887, time 251.86ms, mfu 11.73%\n",
            "iter 4720: loss 1.3659, time 249.67ms, mfu 11.75%\n",
            "iter 4730: loss 1.3791, time 248.06ms, mfu 11.77%\n",
            "iter 4740: loss 1.3812, time 249.36ms, mfu 11.79%\n",
            "step 4750: train loss 1.3312, val loss 1.3860\n",
            "saving checkpoint to out-arabicpoetry-char-adjusted\n",
            "iter 4750: loss 1.3748, time 32142.29ms, mfu 10.62%\n",
            "iter 4760: loss 1.3644, time 249.94ms, mfu 10.75%\n",
            "iter 4770: loss 1.3810, time 251.21ms, mfu 10.86%\n",
            "iter 4780: loss 1.3807, time 249.54ms, mfu 10.97%\n",
            "iter 4790: loss 1.3755, time 250.73ms, mfu 11.06%\n",
            "iter 4800: loss 1.3846, time 252.31ms, mfu 11.13%\n",
            "iter 4810: loss 1.3739, time 251.76ms, mfu 11.20%\n",
            "iter 4820: loss 1.3752, time 251.07ms, mfu 11.26%\n",
            "iter 4830: loss 1.3701, time 252.05ms, mfu 11.32%\n",
            "iter 4840: loss 1.3843, time 249.86ms, mfu 11.38%\n",
            "iter 4850: loss 1.3659, time 249.34ms, mfu 11.43%\n",
            "iter 4860: loss 1.3718, time 249.07ms, mfu 11.49%\n",
            "iter 4870: loss 1.3846, time 248.88ms, mfu 11.53%\n",
            "iter 4880: loss 1.3874, time 248.78ms, mfu 11.58%\n",
            "iter 4890: loss 1.3686, time 249.07ms, mfu 11.61%\n",
            "iter 4900: loss 1.3835, time 249.56ms, mfu 11.65%\n",
            "iter 4910: loss 1.3849, time 251.00ms, mfu 11.67%\n",
            "iter 4920: loss 1.3662, time 251.32ms, mfu 11.68%\n",
            "iter 4930: loss 1.3912, time 252.62ms, mfu 11.69%\n",
            "iter 4940: loss 1.3926, time 252.57ms, mfu 11.70%\n",
            "iter 4950: loss 1.3796, time 252.55ms, mfu 11.71%\n",
            "iter 4960: loss 1.3789, time 249.95ms, mfu 11.73%\n",
            "iter 4970: loss 1.3793, time 250.93ms, mfu 11.74%\n",
            "iter 4980: loss 1.3850, time 249.03ms, mfu 11.76%\n",
            "iter 4990: loss 1.3795, time 250.47ms, mfu 11.78%\n",
            "step 5000: train loss 1.3293, val loss 1.3838\n",
            "saving checkpoint to out-arabicpoetry-char-adjusted\n",
            "iter 5000: loss 1.3718, time 31888.60ms, mfu 10.61%\n"
          ]
        }
      ],
      "source": [
        "!python3 train.py config/train_arabicpoetry_char.py --out_dir=\"out-arabicpoetry-char-adjusted\" --batch_size=256 --n_layer=12 --n_head=12"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ydcJlS1aYyTc"
      },
      "source": [
        "### Test our models (Generate poems)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qIKQNZsWZIi5"
      },
      "source": [
        "#### A. nanoGPT model with default parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l1pa_X2LZDTY",
        "outputId": "ead37315-c04d-4641-d5c4-6b4a1749973a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overriding: out_dir = out-arabicpoetry-char-default\n",
            "number of parameters: 10.64M\n",
            "Loading meta from data/arabicpoetry_char/meta.pkl...\n",
            "\n",
            "ويختال كل معاني    من الملك والمستفاد\n",
            "فحرص الدار أصغر    حرص من العرين وراد\n",
            "على أن أزالوا بالبرد    وراحوا بالموت والبرد\n",
            "وبعد الهادي المزيد    وبعد الترديد\n",
            "وبالباع يسقط في    ملوك المحمود والعند\n",
            "ووالدا من العود    وجاء مرتعد السعد\n",
            "وبالحق يهدي للغو    مى وهو الصليح الشهد\n",
            "فأنت فيه شادوا الفو    ع بلا صليح ولا رقد\n",
            "وخالف بالله والسعد    ما للبقاء المنطق العقد\n",
            "وساقه المشرق من ولج    ت تقد ومن أقصى المشرق\n",
            "وأمسى برودانه في    الأسماع والمبرق\n",
            "فأين الوجود والبها    يحمي الضعاف والوجد\n",
            "وكل الحق أول أول    \n",
            "---------------\n",
            "\n",
            "وأقذت به قبل الوجود بواكف    لكن بمن حتم ومن لا يتعب\n",
            "أرى الله يوما فتحسب من وصل    فما عن وصلكم من أم أنت والحب\n",
            "وأولت إلا بين العز منهم    لقد طلبوا من عز منك ومن ثبوا\n",
            "فباتوا منارا فلا يساموا ولا    تباهي وكن من نابوا ولا عبوا\n",
            "فرب كوكب إبراهيم واحد    وقد كان في الأمر والأمر ذاك والخب\n",
            "مقدامة لم تستر إلا لمعنى    ولا تستر عرفان شر إلى عرش ولا\n",
            "يسامر من شاء في الشرق أرسله    يبيت وأن يبلغ الشرق في الشرق والرجب\n",
            "فمن الموت يسدي الحق بالحق قد    فرد اليتامى والكواكب للحب\n",
            "أطال عليه من ورد الله عامرا    \n",
            "---------------\n",
            "\n",
            "ومن يترك المعروف في الورق    ويترك في ظل أو ندي\n",
            "إذا ما الفتى لم يعرف بها    تملك ما يبغي بأن ترى\n",
            "فلو تعدل في العهد الذي    على الورى والسما لم يعد\n",
            "إذا ما ذكر العهد أن يرى    من النور الذي لا يحد\n",
            "\n",
            "يا من يقول لي بما طال    في كل ما في الأحقاد من ناد\n",
            "لم يكن لي بالله في السحب راحة    حتى يعادى لمن يعاديني بعاد\n",
            "فداؤك بالمعلوم أن بثغره    جمع القوم أم الغات أو الوفد\n",
            "من قبل هذا السيف والسيف المنتدي    عن خليلك كان ذلك المعتدي\n",
            "وتحت ظني السوء في صفو مزجه    وتمحو مزج الأنام إن سواك ومن جدوا\n",
            "أجمل به سكنا \n",
            "---------------\n",
            "\n",
            "بربح له قلبا حسنت فكم    عرفت إلى الترك من أبوابه\n",
            "ولا تقل رياضه الملاح    وأنت له حين تهاب كرابه\n",
            "وإن تلك الطرف الضبيع مضاب    أبا الدين أبدا لها نجابه\n",
            "ومن أهل من يزيد شجوا له    وشمس رمان يكون ضبابه\n",
            "يفتقر الشوق شهدا على النعا    ويكون عن سنن أعز نوابه\n",
            "ويمسي ويبقى سلمه بالمط    ر وأهل النعام له كتابه\n",
            "واليوم مدح بالمرء عابا    وكل رضيع في المرء خابه\n",
            "واليوم من مهمه يجلو ولم    يحامله حالا بالقرابه\n",
            "هاك الشباب ومن يصحبه    من ذا يصحبه صوب فكابه\n",
            "هاك الشباب الشديد وما    بالعرش للبيت الغبابه\n",
            "يا باب الس\n",
            "---------------\n",
            "\n",
            "إن الملائك إبراهيم بطلعته    أمر الرسالة والأشياء بالأسد\n",
            "فلا عيب إلا أن جئت أن أرى    أحبابنا العرباء والإكبار والعد\n",
            "لكن لما شكرت قلوب الضيم لا أرى    إلا ولا كل يوم في الطرس والعد\n",
            "لقد دخلت عنا الأيام ما أردت    وقد أغردت أن تنفع البيض إلى الشهد\n",
            "فالعدل ما لقد عد الظن والحلى    وما هو إلا في العيش والعيش والوهد\n",
            "إذا ألقت من الأيام أن أقمت بها    عليك فإن المآذن الشيخ من أهدي\n",
            "فإن تقم إلا الشرع أعيا أبا    فإن شئت إلا الشرع عنك وأعيدا\n",
            "لئن كنت من وقف البيض زارت بما    سمعت بما تجتاز السمع والورد\n",
            "فلا \n",
            "---------------\n",
            "\n",
            "وبنت السماء وجادت له أسد    وبعض حال الماء والأنداء\n",
            "عند الجواد المؤمل في أعضائه    بدر البوادر من أحضانه الستر\n",
            "حتى إراد العلوم حياته    في من ينال الألباب والأعصاء\n",
            "فمذ ولى القبائل في ظلماته    فالبائس المجروح تكدير والشكر\n",
            "كلما تعامى الليالي بالكرى    والمجد في فضل القصد في أسفاره\n",
            "يا ليته أنت أدري الخطاب فإنني    أعلنت نفسي أو هداي أنت العمر\n",
            "ولقد علم الدهر بالعرب تقصر من    نصائح التأويل من أحلامه البحر\n",
            "وخذ بي في الفلك البريء وقد رأيت    ألا في الناس أو كنت فيه أنت العذر\n",
            "أنت الذي أنت من صوب العدا\n",
            "---------------\n",
            "\n",
            "قالت الأتراح والأسد البالي    \n",
            "\n",
            "جسمي ساحره وهو الأنام    \n",
            "أسكر في البحر من بعد خير ربي    \n",
            "واسقني من حواه من بعد ما قد حاولت    \n",
            "فكأنما عزيزة يستبيح    \n",
            "على جسمها فتأرجت وما راولت    \n",
            "فشوقت عبرات تصبحت أيام مراتبتي    \n",
            "فتسمعت في مياديها وتبكيتي    \n",
            "فأرهبت في أرواح المريد مباركتي    \n",
            "وعدت منها والصبا ما يرويت    \n",
            "والمحب يلذ البحر في أسماعها    \n",
            "والأربع الحسن من ذا ينوي في أحبتي    \n",
            "والنوم يفرح الله مسك ما يصحبها    \n",
            "والحب يفرح الله في طي مسكنها    \n",
            "والمختار ينفس ساقي السهاد بها    \n",
            "\n",
            "أستغفر الله و\n",
            "---------------\n",
            "\n",
            "فلما أصبحت أحرار بشرا    لفرط الإسلام والإيجاد\n",
            "فأي فضل وفرط أني    أبدا فالدهر قد أمادوا\n",
            "فإن لم يعرف في فلك النا    س فلا تر في الإيجاد\n",
            "فبي روضة الله ما بها    أنفاس ولا أستار الشراد\n",
            "أجاد في أرض صلد عليه    فيفيض عنه على جهاد\n",
            "فكم من رجال أضل به    في الله دار دون المكاد\n",
            "لم يحسب الرحمن إلا    ولم يحسب إلا أمين\n",
            "ما لي أن أين الأمين    وليس لي أمين\n",
            "ما لي أن وارد في    حسود ولا أنني تعين\n",
            "بك المرء إلا أنني    خلقت بالحظ وهي دون\n",
            "يا هام لبنان سالت    مني كل من العين\n",
            "وتبكيني بعد عيني    ما هي للمرء لها خ\n",
            "---------------\n",
            "\n",
            "لا تلفت به يوما ولا من يدا    نظمت فؤادي لو تبدى به الحسدا\n",
            "وأكرم به يوما سؤلت ولا جعل    لغير فتى جل الكرام الأولى\n",
            "أسد لك الشام يوم كان قومه    وغل على هام البلاد الموحدا\n",
            "أسكرت في الصين الحياة وأنت في    أسكندر منه في العراق منحدا\n",
            "أسدى الملائك في صرف اللباب إلى    أذهل أوفى من العراق وندا\n",
            "أسدى ولم يرع عيشا من الهوى    أن أسدى إلى حب الضحى مجدا\n",
            "لو كان خير الصب والأنس قد رضعت    لحكمه بين السبيل وسره العدى\n",
            "أم كان يخشى في الشباب وأنت وال    ملك أدركت فيها من الجهد أسعدا\n",
            "أعربت قلبي فالنوى أيقظت    ن\n",
            "---------------\n",
            "\n",
            "قم أنا شاكر وهاشم روحي    بعتب يجور في العذب شاكر\n",
            "قد لاح أن هذا الذي نشرت    بيدي سنان الهوى حائر\n",
            "لا أنس أن تعدل في الأرض من    بعد ادكار ولا أبكار\n",
            "لا أنس بالأرض إلا مع الأرض    يجري لبس النيل والهواجر\n",
            "فالبشر يلقى لقي الدمع والأمن    والبحر يجري من طيب المقامر\n",
            "جوع الوجود في الخدود وكلها    إن فارقت الظنون لها متاخر\n",
            "وتزوي الأفق في الأرض أسلم ما    يصلح الأسرار في الأيام ناظر\n",
            "وتزيد بالحكم في زمن كأنه    تزوير ما يشتهي الأنغام ناظر\n",
            "وما استطعت من الأحزان قاسمة    وأقلب في زمن الأسرار إنجاد\n",
            "وما أدخلت\n",
            "---------------\n"
          ]
        }
      ],
      "source": [
        "!python sample.py --out_dir=out-arabicpoetry-char-default"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eCkRjJMEZj3y"
      },
      "source": [
        "#### B. nanoGPT model with adjusted parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dKB-w8m0lif_",
        "outputId": "94d2b32d-cc81-443e-e679-6ddea2f55f72"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overriding: out_dir = out-arabicpoetry-char-adjusted\n",
            "number of parameters: 21.26M\n",
            "Loading meta from data/arabicpoetry_char/meta.pkl...\n",
            "\n",
            "ويختم بالمعالي والمعالي    ويضرب بالمعارف والمعالي\n",
            "غدا للحرب من نسل وهندي    ومن فخر الفتوح من النزال\n",
            "له في كل حادثة يد    على يده أراه من الرحال\n",
            "هو البدر المضيء عليه ذكرى    ملوك الأرض زانت في الوصال\n",
            "ومن فرعون في الشرف المفدى    هو البحر المفدى في المآل\n",
            "هو السلطان سيان المعالي    هو الشهم المعظم في الكوالي\n",
            "أقام خطابه في كل خطب    وذم على الضراغم في المعالي\n",
            "هو العلياء من بعد التتامي    ومن عجب الشمائل من عوال\n",
            "ومن في ليلة المختار سارت    يضيء ببرج وجه وانتقال\n",
            "ومن هم الأنام بهم كرام    أقاموا بالص\n",
            "---------------\n",
            "\n",
            "وأقعد بنفسي صبرا جميلا    بأن الصبر للتذكار ينهى\n",
            "وأعرض عن أويقاتي كثيرا    ووصل الحب للتنزيه دمه\n",
            "وأكثر في الحوادث من حياتي    وأجزع في الحياة وأنت فهمه\n",
            "فما من دون ذاك النطق إلا    بأن تضرب وتفرس من جهوله\n",
            "ومن يك طائفا بالخوف تنفي    وينفذ كل من يهواه يهوى\n",
            "ويصبح في الممالك كل بذل    به الأقوام لا ترعوي خلوله\n",
            "وما الأعمال إلا رافعات    تخالس في المفاخر من نبيله\n",
            "إذا الأحياء لم يبرح زمانا    يموت ولا يعادلها جزيله\n",
            "وإنا في السداد لنا بذل    وإن ساء السداد لنا بطوله\n",
            "حللنا أن يعود إلى معاد    ترانا للعلى\n",
            "---------------\n",
            "\n",
            "ومن يتخير إلى الله قلبه    سوى تخته للظالمين مقيم\n",
            "بهم يتقي الله العظيم معزز    ويمحوه إرثا للملوك عظيم\n",
            "تلقاه من حلم الرشاد على الورى    فمن دونه الإنسان والتعظيم\n",
            "أشد الردى وردا ونفسا ومنطقا    وفي محفل الإيمان والترحيم\n",
            "وكم لك في الدنيا مقام وآله    ولكنه لم ينكر التحكيم\n",
            "فدم في عمود الحق سعيك أنه    نظير على دار المعارف ظلم\n",
            "أبثك يا سعد الكتاب وأهله    وأحسابه دقت وقلبك يهمي\n",
            "سيبقى حياة المسلمين حياتهم    فكيف يرى المستسلمين ويرحم\n",
            "تبث الحياة المسلمين لذكرهم    بعيدا وتشريفا ويشفي ويحكم\n",
            "وما كل ذكر ل\n",
            "---------------\n",
            "\n",
            "بربح لطف السعد منه بما انتضى    إليه ركاب البين من كل جانب\n",
            "خميس المعاني أنت تحكي محاسن ال    علا الدهر من حسن السنا والمناقب\n",
            "عليه صلاة الله والآل سرمدا    وآل معالي الشان والغير واجب\n",
            "رفيق الهنا والخير والخير والشهدا    \n",
            "تعالى إليك اليوم والنور والضحى    من الوجه والإشراق واللؤلؤ الأندى\n",
            "ولم يك غير البر ما كان حاكما    ولم يك في آفاقها النور أن يسدى\n",
            "ولكنها ما كان يحصر أولا    ويفخر في إيفائها الهام والرشدا\n",
            "لئن كنت لا تعطي الحياة فإنها    ترد لها الأيام تشرد أو تجدى\n",
            "ولا تركب الموتى يزيد عدوها    فت\n",
            "---------------\n",
            "\n",
            "إن الملائك غبطة العباس وال    أرواح والإصلاح والإرباط\n",
            "هي نفس عين الله دون محمد    روح الحبيب من الحبيب الهاطي\n",
            "يا رب هاك حلى المحيا فاغمدي    إن الحياة من الحياة سواطي\n",
            "أجني الحياة وما جنيت من الهوى    والله من يبغي الحياة يواطي\n",
            "فانشد ولا تطلب لها فيما جنى    من خائف كلف وحسرى خاطي\n",
            "مهلا فقد نادى الحياة وغرها    والدهر غر من ندى أحلاط\n",
            "الفن يبقى والحياة نوازع    كالشمس تبدو والنهار تشاط\n",
            "\n",
            "والشمس تعبث أبيضا    في الأفق ناجية حجاز\n",
            "وبدا العقيق منقشا    من بعد زارتها الرضاض\n",
            "والكون يجمع بالسفين    بظلمة ي\n",
            "---------------\n",
            "\n",
            "وبات السلم يسجد يوم مجد    فطاعته الحصون المصرعات\n",
            "فما هذا الشجاعة من جديد    على أن الشجاعة مطلقات\n",
            "وما أدب ستلهو بالمزايا    وقد مضت وقلب الناهضات\n",
            "وما هذا الشجاعة من ذويه    وأنت رفيق ذكراك الحياة\n",
            "وما هذي الحصون وما هذي    إذا ما مر بي لهج الحياة\n",
            "رأيتك والكتاب فما ترقى    وما ترقى إذا حانت هبات\n",
            "هنالك من غريم في سكون    خلاء الدين معتنق الشهات\n",
            "شهودك أن تدوم وأنت روح    وأن لنا البكاء وأنت روح\n",
            "تركت الأمر يخطر في سماء    فأبصر في الهوى عجزا لذات\n",
            "فلو أني وفكر والأماني    لما أبصرت لي ما من صفاتي\n",
            "ولك\n",
            "---------------\n",
            "\n",
            "قالت الأخبار ماذا يفعلون    والشجى يحسد إذ يحسد\n",
            "يا شريف العصر عهد الشام    بعد فقد الصبح بعد الأنجم\n",
            "ليتهم لم ينصروا للبحر عن    دهرهم حكم وعود علقم\n",
            "هي كالبحر إذا أبدى وبدا    نوره في أفقها مستتئدا\n",
            "وإذا أمست مرابع السما    من خليل الشمس تروى الأنجما\n",
            "فأرانا في أريك أمهم    مبدءا من أنهم ما وهموا\n",
            "آثروا ما يرتجى لما دجى    ولكم من أنفس أو يسأم\n",
            "فهم الآثار والآثار في    نور هذا الشمس لم يكتمهم\n",
            "كفروا الأقدار ما أحرصها    أيها السامي الذرى هل أكرموا\n",
            "فلنبك السمع ما قارفه    من سليمان بلا جاه وذم\n",
            "لا يبالو\n",
            "---------------\n",
            "\n",
            "فلما أتيت من الخطب بالأسى    وأحسنت أن يعجز النفس مفسدا\n",
            "فكم أنت من موت إذا دمت قائدا    وكم من فتى يدري بأن لا تجلدا\n",
            "ولما أردت الحزم أجريت وحده    وأكملت فيه الأمر سبلا مؤيدا\n",
            "وكنت أرى جيش العداة كأنما    به عدم الجيش الذي قد ترددا\n",
            "وما حسب الحساد إلا كأنما    فدته المنى شم الحسام وأرشدا\n",
            "وما جعل السلطان في كل جانب    ولكنه في الأرض يأتي مقلدا\n",
            "وما المرء إلا العدل تشريف حقه    وينصره في العالمين محمدا\n",
            "إذا كان أفضل الله في الذكر يومه    فما ضر للأقوام إلا تمجدا\n",
            "إذا ذكر الأعداء في الدين هاشم    على مث\n",
            "---------------\n",
            "\n",
            "لا تلوموا تلك الحياة فإن ال    موت في عيشها الجريح المحيد\n",
            "حيث لم يدفع الغرام فلا تجد    من يسود الجدود كيف يسود\n",
            "حيث لم يدر بالحياة ولكن    ما لجد بقاؤه ما يصيد\n",
            "كل من وحدة أقام وأبقى    رب حين ترى السماء السدود\n",
            "كم خبا من عرى النفوس وأمسى    فيه نيرانها البديع البعيد\n",
            "ذهب الفتنة التي نال نظما    ليس تبرح عيشة من مزيد\n",
            "ولكم من سماء دار بنينا    والأماني تزخرف والعنود\n",
            "أنت يا دولة الأديب فقد لا    يدرك المال والعمام قصيدي\n",
            "حسب الشعب أن تخط فؤادي    وأراه الشعوب من الجحود\n",
            "أنا معنى فقدت روحي وإلا    وأران\n",
            "---------------\n",
            "\n",
            "قم أنت بالعز واشرب لابسا مرحا    وأصدر العز في أعلى منازله\n",
            "إن كان يقصد قصد العز يقصده    فذلك العز للأعداء جاهله\n",
            "فأي نعماء تدعوني وإن كمنت    أبكي وتسكن آمالي وأكمله\n",
            "إن المروءة في الأرواح عن ثقة    والعز مرتبة والعز أفضله\n",
            "إن المراد بإنقاذ فليس لمن    للعالمين به عن وصف منزله\n",
            "لم ينصرف بين أهل الفضل والظفر    ولم يكن لي سيف الفضل من عمر\n",
            "دع المساعير إن تحصل سرائرها    يوما وحاصلها عن مطلع البدر\n",
            "فإن تكن مستعينا ما يشاء به    فإنه لك قد أحرزت من أمرا\n",
            "فما درى أنه يحصي جواهره    من أعظم العدل في سعد وف\n",
            "---------------\n"
          ]
        }
      ],
      "source": [
        "!python sample.py --out_dir=out-arabicpoetry-char-adjusted"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "mVOqNGwGA_c9",
        "o_nEnDD8c1oG",
        "T0Z0xnZLdB8X",
        "qPNhduzx-XhF",
        "LYoQlud1Gg0v",
        "dEyLfwsfGwDF",
        "qIKQNZsWZIi5",
        "eCkRjJMEZj3y"
      ],
      "gpuType": "V100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
